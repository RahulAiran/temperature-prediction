{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.read_csv('POWER_SinglePoint_Daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DY</th>\n",
       "      <th>T2M_RANGE</th>\n",
       "      <th>TS</th>\n",
       "      <th>T2MWET</th>\n",
       "      <th>T2M_MAX</th>\n",
       "      <th>T2M_MIN</th>\n",
       "      <th>T2M</th>\n",
       "      <th>PS</th>\n",
       "      <th>QV2M</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>PRECTOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.66591</td>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.99</td>\n",
       "      <td>18.43</td>\n",
       "      <td>13.07</td>\n",
       "      <td>24.83</td>\n",
       "      <td>13.84</td>\n",
       "      <td>18.26</td>\n",
       "      <td>94.09</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>71.74</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.66591</td>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.06</td>\n",
       "      <td>17.90</td>\n",
       "      <td>13.40</td>\n",
       "      <td>24.30</td>\n",
       "      <td>12.23</td>\n",
       "      <td>17.85</td>\n",
       "      <td>94.35</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>75.15</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.66591</td>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.50</td>\n",
       "      <td>18.39</td>\n",
       "      <td>13.23</td>\n",
       "      <td>25.03</td>\n",
       "      <td>12.53</td>\n",
       "      <td>18.15</td>\n",
       "      <td>94.52</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.66591</td>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13.91</td>\n",
       "      <td>19.43</td>\n",
       "      <td>14.21</td>\n",
       "      <td>26.79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>19.26</td>\n",
       "      <td>94.56</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>72.64</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.66591</td>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13.59</td>\n",
       "      <td>19.68</td>\n",
       "      <td>12.02</td>\n",
       "      <td>27.15</td>\n",
       "      <td>13.56</td>\n",
       "      <td>19.86</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>60.66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LAT       LON  YEAR  MO  DY  T2M_RANGE     TS  T2MWET  T2M_MAX  \\\n",
       "0  18.66591  73.77031  2015   1   1      10.99  18.43   13.07    24.83   \n",
       "1  18.66591  73.77031  2015   1   2      12.06  17.90   13.40    24.30   \n",
       "2  18.66591  73.77031  2015   1   3      12.50  18.39   13.23    25.03   \n",
       "3  18.66591  73.77031  2015   1   4      13.91  19.43   14.21    26.79   \n",
       "4  18.66591  73.77031  2015   1   5      13.59  19.68   12.02    27.15   \n",
       "\n",
       "   T2M_MIN    T2M     PS      QV2M   RH2M  PRECTOT  \n",
       "0    13.84  18.26  94.09  0.010020  71.74     0.36  \n",
       "1    12.23  17.85  94.35  0.010200  75.15     0.08  \n",
       "2    12.53  18.15  94.52  0.010078  73.00     0.00  \n",
       "3    12.89  19.26  94.56  0.010747  72.64     0.00  \n",
       "4    13.56  19.86  94.57  0.009309  60.66     0.00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('LAT',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LON</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DY</th>\n",
       "      <th>T2M_RANGE</th>\n",
       "      <th>TS</th>\n",
       "      <th>T2MWET</th>\n",
       "      <th>T2M_MAX</th>\n",
       "      <th>T2M_MIN</th>\n",
       "      <th>T2M</th>\n",
       "      <th>PS</th>\n",
       "      <th>QV2M</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>PRECTOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.99</td>\n",
       "      <td>18.43</td>\n",
       "      <td>13.07</td>\n",
       "      <td>24.83</td>\n",
       "      <td>13.84</td>\n",
       "      <td>18.26</td>\n",
       "      <td>94.09</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>71.74</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.06</td>\n",
       "      <td>17.90</td>\n",
       "      <td>13.40</td>\n",
       "      <td>24.30</td>\n",
       "      <td>12.23</td>\n",
       "      <td>17.85</td>\n",
       "      <td>94.35</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>75.15</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.50</td>\n",
       "      <td>18.39</td>\n",
       "      <td>13.23</td>\n",
       "      <td>25.03</td>\n",
       "      <td>12.53</td>\n",
       "      <td>18.15</td>\n",
       "      <td>94.52</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13.91</td>\n",
       "      <td>19.43</td>\n",
       "      <td>14.21</td>\n",
       "      <td>26.79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>19.26</td>\n",
       "      <td>94.56</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>72.64</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13.59</td>\n",
       "      <td>19.68</td>\n",
       "      <td>12.02</td>\n",
       "      <td>27.15</td>\n",
       "      <td>13.56</td>\n",
       "      <td>19.86</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>60.66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.28</td>\n",
       "      <td>17.77</td>\n",
       "      <td>34.20</td>\n",
       "      <td>19.29</td>\n",
       "      <td>25.51</td>\n",
       "      <td>94.40</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>37.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>15.55</td>\n",
       "      <td>24.90</td>\n",
       "      <td>17.81</td>\n",
       "      <td>32.82</td>\n",
       "      <td>17.27</td>\n",
       "      <td>23.88</td>\n",
       "      <td>94.39</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>46.53</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>18.16</td>\n",
       "      <td>25.21</td>\n",
       "      <td>18.36</td>\n",
       "      <td>34.02</td>\n",
       "      <td>15.86</td>\n",
       "      <td>24.02</td>\n",
       "      <td>94.33</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>49.06</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>73.77031</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1909 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LON  YEAR  MO  DY  T2M_RANGE      TS  T2MWET  T2M_MAX  T2M_MIN  \\\n",
       "0     73.77031  2015   1   1      10.99   18.43   13.07    24.83    13.84   \n",
       "1     73.77031  2015   1   2      12.06   17.90   13.40    24.30    12.23   \n",
       "2     73.77031  2015   1   3      12.50   18.39   13.23    25.03    12.53   \n",
       "3     73.77031  2015   1   4      13.91   19.43   14.21    26.79    12.89   \n",
       "4     73.77031  2015   1   5      13.59   19.68   12.02    27.15    13.56   \n",
       "...        ...   ...  ..  ..        ...     ...     ...      ...      ...   \n",
       "1904  73.77031  2020   3  19      14.91   26.28   17.77    34.20    19.29   \n",
       "1905  73.77031  2020   3  20      15.55   24.90   17.81    32.82    17.27   \n",
       "1906  73.77031  2020   3  21      18.16   25.21   18.36    34.02    15.86   \n",
       "1907  73.77031  2020   3  22    -999.00 -999.00 -999.00  -999.00  -999.00   \n",
       "1908  73.77031  2020   3  23    -999.00 -999.00 -999.00  -999.00  -999.00   \n",
       "\n",
       "         T2M      PS        QV2M    RH2M  PRECTOT  \n",
       "0      18.26   94.09    0.010020   71.74     0.36  \n",
       "1      17.85   94.35    0.010200   75.15     0.08  \n",
       "2      18.15   94.52    0.010078   73.00     0.00  \n",
       "3      19.26   94.56    0.010747   72.64     0.00  \n",
       "4      19.86   94.57    0.009309   60.66     0.00  \n",
       "...      ...     ...         ...     ...      ...  \n",
       "1904   25.51   94.40    0.008190   37.86     0.00  \n",
       "1905   23.88   94.39    0.009140   46.53     0.00  \n",
       "1906   24.02   94.33    0.009724   49.06     0.01  \n",
       "1907 -999.00 -999.00 -999.000000 -999.00  -999.00  \n",
       "1908 -999.00 -999.00 -999.000000 -999.00  -999.00  \n",
       "\n",
       "[1909 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['LON', 'YEAR', 'DY', 'T2M_RANGE', 'TS', 'T2MWET', 'PS', 'QV2M', 'RH2M', 'PRECTOT'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MO</th>\n",
       "      <th>T2M_MAX</th>\n",
       "      <th>T2M_MIN</th>\n",
       "      <th>T2M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24.83</td>\n",
       "      <td>13.84</td>\n",
       "      <td>18.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24.30</td>\n",
       "      <td>12.23</td>\n",
       "      <td>17.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25.03</td>\n",
       "      <td>12.53</td>\n",
       "      <td>18.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>26.79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>19.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>27.15</td>\n",
       "      <td>13.56</td>\n",
       "      <td>19.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>3</td>\n",
       "      <td>34.20</td>\n",
       "      <td>19.29</td>\n",
       "      <td>25.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>3</td>\n",
       "      <td>32.82</td>\n",
       "      <td>17.27</td>\n",
       "      <td>23.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>3</td>\n",
       "      <td>34.02</td>\n",
       "      <td>15.86</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>3</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>3</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MO  T2M_MAX  T2M_MIN     T2M\n",
       "0      1    24.83    13.84   18.26\n",
       "1      1    24.30    12.23   17.85\n",
       "2      1    25.03    12.53   18.15\n",
       "3      1    26.79    12.89   19.26\n",
       "4      1    27.15    13.56   19.86\n",
       "...   ..      ...      ...     ...\n",
       "1904   3    34.20    19.29   25.51\n",
       "1905   3    32.82    17.27   23.88\n",
       "1906   3    34.02    15.86   24.02\n",
       "1907   3  -999.00  -999.00 -999.00\n",
       "1908   3  -999.00  -999.00 -999.00\n",
       "\n",
       "[1909 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df)\n",
    "X = np.array([[data[i+3][0],\n",
    "               data[i][1],\n",
    "               data[i][2],\n",
    "               data[i+1][1],\n",
    "               data[i+1][2],\n",
    "               data[i+2][1],\n",
    "               data[i+1][2],\n",
    "               data[i+3][3]] for i in range(1903)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[:, :7], X[:, -1], test_size=0.15, random_state=101, shuffle = True)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\RAHUL AIRAN\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1617, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics\n",
    "model = Sequential()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse',metrics=[metrics.mae, metrics.categorical_accuracy])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop=EarlyStopping(monitor='val_loss',verbose=1,patience=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1617 samples, validate on 286 samples\n",
      "Epoch 1/600\n",
      "1617/1617 [==============================] - 0s 287us/sample - loss: 559.9906 - mean_absolute_error: 23.4339 - categorical_accuracy: 1.0000 - val_loss: 530.1728 - val_mean_absolute_error: 22.7933 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/600\n",
      "1617/1617 [==============================] - 0s 48us/sample - loss: 498.0326 - mean_absolute_error: 22.0941 - categorical_accuracy: 1.0000 - val_loss: 434.1878 - val_mean_absolute_error: 20.6356 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 346.0706 - mean_absolute_error: 18.3534 - categorical_accuracy: 1.0000 - val_loss: 221.5152 - val_mean_absolute_error: 14.7540 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: 111.3447 - mean_absolute_error: 9.9312 - categorical_accuracy: 1.0000 - val_loss: 21.1109 - val_mean_absolute_error: 4.2225 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/600\n",
      "1617/1617 [==============================] - 0s 53us/sample - loss: 8.4412 - mean_absolute_error: 2.1906 - categorical_accuracy: 1.0000 - val_loss: 6.1001 - val_mean_absolute_error: 1.8391 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/600\n",
      "1617/1617 [==============================] - 0s 52us/sample - loss: 5.8967 - mean_absolute_error: 1.7529 - categorical_accuracy: 1.0000 - val_loss: 5.8302 - val_mean_absolute_error: 1.7448 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/600\n",
      "1617/1617 [==============================] - 0s 52us/sample - loss: 5.7242 - mean_absolute_error: 1.7261 - categorical_accuracy: 1.0000 - val_loss: 5.6750 - val_mean_absolute_error: 1.7127 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/600\n",
      "1617/1617 [==============================] - 0s 62us/sample - loss: 5.5837 - mean_absolute_error: 1.6846 - categorical_accuracy: 1.0000 - val_loss: 5.5504 - val_mean_absolute_error: 1.7126 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/600\n",
      "1617/1617 [==============================] - 0s 54us/sample - loss: 5.4377 - mean_absolute_error: 1.6743 - categorical_accuracy: 1.0000 - val_loss: 5.3874 - val_mean_absolute_error: 1.6793 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/600\n",
      "1617/1617 [==============================] - 0s 59us/sample - loss: 5.2901 - mean_absolute_error: 1.6467 - categorical_accuracy: 1.0000 - val_loss: 5.2461 - val_mean_absolute_error: 1.6652 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/600\n",
      "1617/1617 [==============================] - 0s 60us/sample - loss: 5.1470 - mean_absolute_error: 1.6349 - categorical_accuracy: 1.0000 - val_loss: 5.0842 - val_mean_absolute_error: 1.6371 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 5.0065 - mean_absolute_error: 1.6092 - categorical_accuracy: 1.0000 - val_loss: 4.9389 - val_mean_absolute_error: 1.6226 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: 4.8432 - mean_absolute_error: 1.5884 - categorical_accuracy: 1.0000 - val_loss: 4.7637 - val_mean_absolute_error: 1.5857 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 4.6981 - mean_absolute_error: 1.5663 - categorical_accuracy: 1.0000 - val_loss: 4.6062 - val_mean_absolute_error: 1.5505 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: 4.5486 - mean_absolute_error: 1.5460 - categorical_accuracy: 1.0000 - val_loss: 4.4501 - val_mean_absolute_error: 1.5326 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 4.3980 - mean_absolute_error: 1.5216 - categorical_accuracy: 1.0000 - val_loss: 4.3074 - val_mean_absolute_error: 1.4988 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 4.2639 - mean_absolute_error: 1.5029 - categorical_accuracy: 1.0000 - val_loss: 4.1426 - val_mean_absolute_error: 1.4868 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/600\n",
      "1617/1617 [==============================] - 0s 66us/sample - loss: 4.1185 - mean_absolute_error: 1.4798 - categorical_accuracy: 1.0000 - val_loss: 4.0061 - val_mean_absolute_error: 1.4711 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/600\n",
      "1617/1617 [==============================] - 0s 63us/sample - loss: 3.9636 - mean_absolute_error: 1.4532 - categorical_accuracy: 1.0000 - val_loss: 3.8351 - val_mean_absolute_error: 1.4299 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/600\n",
      "1617/1617 [==============================] - 0s 76us/sample - loss: 3.8239 - mean_absolute_error: 1.4315 - categorical_accuracy: 1.0000 - val_loss: 3.6918 - val_mean_absolute_error: 1.4070 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/600\n",
      "1617/1617 [==============================] - 0s 61us/sample - loss: 3.6896 - mean_absolute_error: 1.4077 - categorical_accuracy: 1.0000 - val_loss: 3.5385 - val_mean_absolute_error: 1.3743 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/600\n",
      "1617/1617 [==============================] - 0s 58us/sample - loss: 3.5422 - mean_absolute_error: 1.3833 - categorical_accuracy: 1.0000 - val_loss: 3.4008 - val_mean_absolute_error: 1.3524 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/600\n",
      "1617/1617 [==============================] - 0s 57us/sample - loss: 3.4133 - mean_absolute_error: 1.3614 - categorical_accuracy: 1.0000 - val_loss: 3.2583 - val_mean_absolute_error: 1.3246 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/600\n",
      "1617/1617 [==============================] - 0s 62us/sample - loss: 3.2807 - mean_absolute_error: 1.3350 - categorical_accuracy: 1.0000 - val_loss: 3.1190 - val_mean_absolute_error: 1.2969 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/600\n",
      "1617/1617 [==============================] - 0s 61us/sample - loss: 3.1602 - mean_absolute_error: 1.3126 - categorical_accuracy: 1.0000 - val_loss: 2.9748 - val_mean_absolute_error: 1.2642 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/600\n",
      "1617/1617 [==============================] - 0s 64us/sample - loss: 3.0270 - mean_absolute_error: 1.2920 - categorical_accuracy: 1.0000 - val_loss: 2.8495 - val_mean_absolute_error: 1.2385 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/600\n",
      "1617/1617 [==============================] - 0s 54us/sample - loss: 2.9130 - mean_absolute_error: 1.2670 - categorical_accuracy: 1.0000 - val_loss: 2.7203 - val_mean_absolute_error: 1.2119 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/600\n",
      "1617/1617 [==============================] - 0s 50us/sample - loss: 2.7896 - mean_absolute_error: 1.2424 - categorical_accuracy: 1.0000 - val_loss: 2.5946 - val_mean_absolute_error: 1.1841 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/600\n",
      "1617/1617 [==============================] - ETA: 0s - loss: 2.6779 - mean_absolute_error: 1.2150 - categorical_accuracy: 1.00 - 0s 46us/sample - loss: 2.6718 - mean_absolute_error: 1.2168 - categorical_accuracy: 1.0000 - val_loss: 2.4626 - val_mean_absolute_error: 1.1529 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: 2.5644 - mean_absolute_error: 1.1972 - categorical_accuracy: 1.0000 - val_loss: 2.3451 - val_mean_absolute_error: 1.1252 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/600\n",
      "1617/1617 [==============================] - 0s 57us/sample - loss: 2.4631 - mean_absolute_error: 1.1729 - categorical_accuracy: 1.0000 - val_loss: 2.2420 - val_mean_absolute_error: 1.1028 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 2.3547 - mean_absolute_error: 1.1501 - categorical_accuracy: 1.0000 - val_loss: 2.1342 - val_mean_absolute_error: 1.0756 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/600\n",
      "1617/1617 [==============================] - 0s 48us/sample - loss: 2.2633 - mean_absolute_error: 1.1323 - categorical_accuracy: 1.0000 - val_loss: 2.0285 - val_mean_absolute_error: 1.0462 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/600\n",
      "1617/1617 [==============================] - 0s 50us/sample - loss: 2.1644 - mean_absolute_error: 1.1049 - categorical_accuracy: 1.0000 - val_loss: 1.9385 - val_mean_absolute_error: 1.0189 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: 2.0834 - mean_absolute_error: 1.0863 - categorical_accuracy: 1.0000 - val_loss: 1.8467 - val_mean_absolute_error: 0.9939 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 2.0089 - mean_absolute_error: 1.0665 - categorical_accuracy: 1.0000 - val_loss: 1.7836 - val_mean_absolute_error: 0.9759 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.9334 - mean_absolute_error: 1.0437 - categorical_accuracy: 1.0000 - val_loss: 1.6951 - val_mean_absolute_error: 0.9487 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.8635 - mean_absolute_error: 1.0291 - categorical_accuracy: 1.0000 - val_loss: 1.6197 - val_mean_absolute_error: 0.9261 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: 1.7993 - mean_absolute_error: 1.0104 - categorical_accuracy: 1.0000 - val_loss: 1.5554 - val_mean_absolute_error: 0.9194 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.7310 - mean_absolute_error: 0.9913 - categorical_accuracy: 1.0000 - val_loss: 1.4824 - val_mean_absolute_error: 0.8875 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: 1.6790 - mean_absolute_error: 0.9782 - categorical_accuracy: 1.0000 - val_loss: 1.4312 - val_mean_absolute_error: 0.8806 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: 1.6355 - mean_absolute_error: 0.9639 - categorical_accuracy: 1.0000 - val_loss: 1.3737 - val_mean_absolute_error: 0.8610 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: 1.5837 - mean_absolute_error: 0.9495 - categorical_accuracy: 1.0000 - val_loss: 1.3290 - val_mean_absolute_error: 0.8474 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.5426 - mean_absolute_error: 0.9360 - categorical_accuracy: 1.0000 - val_loss: 1.2881 - val_mean_absolute_error: 0.8294 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: 1.5109 - mean_absolute_error: 0.9253 - categorical_accuracy: 1.0000 - val_loss: 1.2492 - val_mean_absolute_error: 0.8221 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: 1.4845 - mean_absolute_error: 0.9156 - categorical_accuracy: 1.0000 - val_loss: 1.2159 - val_mean_absolute_error: 0.8072 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: 1.4539 - mean_absolute_error: 0.9107 - categorical_accuracy: 1.0000 - val_loss: 1.1884 - val_mean_absolute_error: 0.7964 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.4263 - mean_absolute_error: 0.8982 - categorical_accuracy: 1.0000 - val_loss: 1.1818 - val_mean_absolute_error: 0.7923 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/600\n",
      "1617/1617 [==============================] - 0s 59us/sample - loss: 1.4016 - mean_absolute_error: 0.8928 - categorical_accuracy: 1.0000 - val_loss: 1.1410 - val_mean_absolute_error: 0.7810 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 1.3861 - mean_absolute_error: 0.8855 - categorical_accuracy: 1.0000 - val_loss: 1.1247 - val_mean_absolute_error: 0.7750 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.3661 - mean_absolute_error: 0.8777 - categorical_accuracy: 1.0000 - val_loss: 1.1051 - val_mean_absolute_error: 0.7745 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.3536 - mean_absolute_error: 0.8721 - categorical_accuracy: 1.0000 - val_loss: 1.0895 - val_mean_absolute_error: 0.7669 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: 1.3351 - mean_absolute_error: 0.8657 - categorical_accuracy: 1.0000 - val_loss: 1.1058 - val_mean_absolute_error: 0.7662 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/600\n",
      "1617/1617 [==============================] - 0s 62us/sample - loss: 1.3410 - mean_absolute_error: 0.8663 - categorical_accuracy: 1.0000 - val_loss: 1.0987 - val_mean_absolute_error: 0.7639 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/600\n",
      "1617/1617 [==============================] - 0s 61us/sample - loss: 1.3272 - mean_absolute_error: 0.8639 - categorical_accuracy: 1.0000 - val_loss: 1.1166 - val_mean_absolute_error: 0.8008 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/600\n",
      "1617/1617 [==============================] - 0s 61us/sample - loss: 1.3167 - mean_absolute_error: 0.8609 - categorical_accuracy: 1.0000 - val_loss: 1.0500 - val_mean_absolute_error: 0.7519 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/600\n",
      "1617/1617 [==============================] - 0s 62us/sample - loss: 1.2983 - mean_absolute_error: 0.8487 - categorical_accuracy: 1.0000 - val_loss: 1.0406 - val_mean_absolute_error: 0.7511 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/600\n",
      "1617/1617 [==============================] - 0s 67us/sample - loss: 1.2982 - mean_absolute_error: 0.8509 - categorical_accuracy: 1.0000 - val_loss: 1.0538 - val_mean_absolute_error: 0.7485 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/600\n",
      "1617/1617 [==============================] - 0s 63us/sample - loss: 1.3146 - mean_absolute_error: 0.8561 - categorical_accuracy: 1.0000 - val_loss: 1.0284 - val_mean_absolute_error: 0.7491 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/600\n",
      "1617/1617 [==============================] - 0s 60us/sample - loss: 1.2804 - mean_absolute_error: 0.8403 - categorical_accuracy: 1.0000 - val_loss: 1.0220 - val_mean_absolute_error: 0.7436 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/600\n",
      "1617/1617 [==============================] - 0s 58us/sample - loss: 1.2834 - mean_absolute_error: 0.8515 - categorical_accuracy: 1.0000 - val_loss: 1.0504 - val_mean_absolute_error: 0.7460 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/600\n",
      "1617/1617 [==============================] - 0s 66us/sample - loss: 1.2916 - mean_absolute_error: 0.8457 - categorical_accuracy: 1.0000 - val_loss: 1.0122 - val_mean_absolute_error: 0.7404 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/600\n",
      "1617/1617 [==============================] - 0s 72us/sample - loss: 1.2621 - mean_absolute_error: 0.8319 - categorical_accuracy: 1.0000 - val_loss: 1.0364 - val_mean_absolute_error: 0.7417 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/600\n",
      "1617/1617 [==============================] - 0s 64us/sample - loss: 1.2723 - mean_absolute_error: 0.8403 - categorical_accuracy: 1.0000 - val_loss: 1.0227 - val_mean_absolute_error: 0.7372 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/600\n",
      "1617/1617 [==============================] - 0s 65us/sample - loss: 1.2564 - mean_absolute_error: 0.8305 - categorical_accuracy: 1.0000 - val_loss: 1.0131 - val_mean_absolute_error: 0.7347 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/600\n",
      "1617/1617 [==============================] - 0s 62us/sample - loss: 1.2544 - mean_absolute_error: 0.8298 - categorical_accuracy: 1.0000 - val_loss: 1.0134 - val_mean_absolute_error: 0.7343 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/600\n",
      "1617/1617 [==============================] - 0s 69us/sample - loss: 1.2425 - mean_absolute_error: 0.8243 - categorical_accuracy: 1.0000 - val_loss: 0.9986 - val_mean_absolute_error: 0.7403 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/600\n",
      "1617/1617 [==============================] - 0s 53us/sample - loss: 1.2424 - mean_absolute_error: 0.8268 - categorical_accuracy: 1.0000 - val_loss: 0.9939 - val_mean_absolute_error: 0.7288 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.2444 - mean_absolute_error: 0.8270 - categorical_accuracy: 1.0000 - val_loss: 0.9968 - val_mean_absolute_error: 0.7414 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/600\n",
      "1617/1617 [==============================] - 0s 53us/sample - loss: 1.2346 - mean_absolute_error: 0.8219 - categorical_accuracy: 1.0000 - val_loss: 0.9907 - val_mean_absolute_error: 0.7376 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/600\n",
      "1617/1617 [==============================] - 0s 60us/sample - loss: 1.2283 - mean_absolute_error: 0.8242 - categorical_accuracy: 1.0000 - val_loss: 0.9787 - val_mean_absolute_error: 0.7249 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/600\n",
      "1617/1617 [==============================] - 0s 63us/sample - loss: 1.2222 - mean_absolute_error: 0.8199 - categorical_accuracy: 1.0000 - val_loss: 0.9751 - val_mean_absolute_error: 0.7276 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/600\n",
      "1617/1617 [==============================] - 0s 62us/sample - loss: 1.2225 - mean_absolute_error: 0.8204 - categorical_accuracy: 1.0000 - val_loss: 0.9724 - val_mean_absolute_error: 0.7210 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/600\n",
      "1617/1617 [==============================] - 0s 56us/sample - loss: 1.2151 - mean_absolute_error: 0.8232 - categorical_accuracy: 1.0000 - val_loss: 0.9827 - val_mean_absolute_error: 0.7349 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/600\n",
      "1617/1617 [==============================] - 0s 57us/sample - loss: 1.2102 - mean_absolute_error: 0.8182 - categorical_accuracy: 1.0000 - val_loss: 0.9651 - val_mean_absolute_error: 0.7229 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: 1.2178 - mean_absolute_error: 0.8186 - categorical_accuracy: 1.0000 - val_loss: 0.9784 - val_mean_absolute_error: 0.7215 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: 1.2166 - mean_absolute_error: 0.8194 - categorical_accuracy: 1.0000 - val_loss: 0.9845 - val_mean_absolute_error: 0.7234 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: 1.1972 - mean_absolute_error: 0.8106 - categorical_accuracy: 1.0000 - val_loss: 0.9556 - val_mean_absolute_error: 0.7184 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/600\n",
      "1617/1617 [==============================] - 0s 68us/sample - loss: 1.1941 - mean_absolute_error: 0.8085 - categorical_accuracy: 1.0000 - val_loss: 0.9541 - val_mean_absolute_error: 0.7133 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/600\n",
      "1617/1617 [==============================] - 0s 57us/sample - loss: 1.1928 - mean_absolute_error: 0.8087 - categorical_accuracy: 1.0000 - val_loss: 1.0118 - val_mean_absolute_error: 0.7362 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/600\n",
      "1617/1617 [==============================] - 0s 59us/sample - loss: 1.2016 - mean_absolute_error: 0.8163 - categorical_accuracy: 1.0000 - val_loss: 0.9590 - val_mean_absolute_error: 0.7146 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/600\n",
      "1617/1617 [==============================] - 0s 78us/sample - loss: 1.1946 - mean_absolute_error: 0.8082 - categorical_accuracy: 1.0000 - val_loss: 0.9431 - val_mean_absolute_error: 0.7098 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/600\n",
      "1617/1617 [==============================] - 0s 55us/sample - loss: 1.1847 - mean_absolute_error: 0.8098 - categorical_accuracy: 1.0000 - val_loss: 0.9477 - val_mean_absolute_error: 0.7104 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/600\n",
      "1617/1617 [==============================] - 0s 60us/sample - loss: 1.1804 - mean_absolute_error: 0.8075 - categorical_accuracy: 1.0000 - val_loss: 0.9430 - val_mean_absolute_error: 0.7137 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/600\n",
      "1617/1617 [==============================] - 0s 60us/sample - loss: 1.1858 - mean_absolute_error: 0.8096 - categorical_accuracy: 1.0000 - val_loss: 0.9405 - val_mean_absolute_error: 0.7123 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/600\n",
      "1617/1617 [==============================] - 0s 61us/sample - loss: 1.1752 - mean_absolute_error: 0.8068 - categorical_accuracy: 1.0000 - val_loss: 0.9558 - val_mean_absolute_error: 0.7121 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/600\n",
      "1617/1617 [==============================] - 0s 58us/sample - loss: 1.1659 - mean_absolute_error: 0.8031 - categorical_accuracy: 1.0000 - val_loss: 0.9325 - val_mean_absolute_error: 0.7040 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/600\n",
      "1617/1617 [==============================] - 0s 78us/sample - loss: 1.1710 - mean_absolute_error: 0.8057 - categorical_accuracy: 1.0000 - val_loss: 0.9311 - val_mean_absolute_error: 0.7079 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/600\n",
      "1617/1617 [==============================] - 0s 81us/sample - loss: 1.1623 - mean_absolute_error: 0.8015 - categorical_accuracy: 1.0000 - val_loss: 0.9243 - val_mean_absolute_error: 0.7022 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/600\n",
      "1617/1617 [==============================] - 0s 52us/sample - loss: 1.1519 - mean_absolute_error: 0.7972 - categorical_accuracy: 1.0000 - val_loss: 0.9316 - val_mean_absolute_error: 0.7026 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/600\n",
      "1617/1617 [==============================] - 0s 52us/sample - loss: 1.1491 - mean_absolute_error: 0.7961 - categorical_accuracy: 1.0000 - val_loss: 0.9197 - val_mean_absolute_error: 0.7006 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/600\n",
      "1617/1617 [==============================] - 0s 55us/sample - loss: 1.1459 - mean_absolute_error: 0.7958 - categorical_accuracy: 1.0000 - val_loss: 0.9814 - val_mean_absolute_error: 0.7465 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/600\n",
      "1617/1617 [==============================] - 0s 53us/sample - loss: 1.1508 - mean_absolute_error: 0.8048 - categorical_accuracy: 1.0000 - val_loss: 0.9214 - val_mean_absolute_error: 0.6992 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/600\n",
      "1617/1617 [==============================] - 0s 52us/sample - loss: 1.1431 - mean_absolute_error: 0.7945 - categorical_accuracy: 1.0000 - val_loss: 0.9180 - val_mean_absolute_error: 0.7022 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: 1.1552 - mean_absolute_error: 0.8027 - categorical_accuracy: 1.0000 - val_loss: 0.9114 - val_mean_absolute_error: 0.6956 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1639 - mean_absolute_error: 0.8077 - categorical_accuracy: 1.0000 - val_loss: 0.9164 - val_mean_absolute_error: 0.6959 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1458 - mean_absolute_error: 0.7954 - categorical_accuracy: 1.0000 - val_loss: 0.9455 - val_mean_absolute_error: 0.7084 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1372 - mean_absolute_error: 0.7920 - categorical_accuracy: 1.0000 - val_loss: 0.9268 - val_mean_absolute_error: 0.6997 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1359 - mean_absolute_error: 0.7968 - categorical_accuracy: 1.0000 - val_loss: 0.9727 - val_mean_absolute_error: 0.7219 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.1312 - mean_absolute_error: 0.7941 - categorical_accuracy: 1.0000 - val_loss: 0.9145 - val_mean_absolute_error: 0.6941 - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.1288 - mean_absolute_error: 0.7936 - categorical_accuracy: 1.0000 - val_loss: 0.9111 - val_mean_absolute_error: 0.6924 - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/600\n",
      "1617/1617 [==============================] - 0s 54us/sample - loss: 1.1285 - mean_absolute_error: 0.7936 - categorical_accuracy: 1.0000 - val_loss: 0.8979 - val_mean_absolute_error: 0.6884 - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1170 - mean_absolute_error: 0.7872 - categorical_accuracy: 1.0000 - val_loss: 0.9012 - val_mean_absolute_error: 0.6894 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.1157 - mean_absolute_error: 0.7891 - categorical_accuracy: 1.0000 - val_loss: 0.8972 - val_mean_absolute_error: 0.6882 - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.1242 - mean_absolute_error: 0.7925 - categorical_accuracy: 1.0000 - val_loss: 0.9007 - val_mean_absolute_error: 0.6957 - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1287 - mean_absolute_error: 0.7959 - categorical_accuracy: 1.0000 - val_loss: 0.9488 - val_mean_absolute_error: 0.7321 - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.1360 - mean_absolute_error: 0.8014 - categorical_accuracy: 1.0000 - val_loss: 0.8946 - val_mean_absolute_error: 0.6850 - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.1177 - mean_absolute_error: 0.7897 - categorical_accuracy: 1.0000 - val_loss: 0.8903 - val_mean_absolute_error: 0.6888 - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1171 - mean_absolute_error: 0.7908 - categorical_accuracy: 1.0000 - val_loss: 0.9031 - val_mean_absolute_error: 0.6992 - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.1111 - mean_absolute_error: 0.7852 - categorical_accuracy: 1.0000 - val_loss: 0.8867 - val_mean_absolute_error: 0.6863 - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1091 - mean_absolute_error: 0.7869 - categorical_accuracy: 1.0000 - val_loss: 0.8839 - val_mean_absolute_error: 0.6829 - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: 1.1112 - mean_absolute_error: 0.7875 - categorical_accuracy: 1.0000 - val_loss: 0.9017 - val_mean_absolute_error: 0.6879 - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: 1.1003 - mean_absolute_error: 0.7828 - categorical_accuracy: 1.0000 - val_loss: 0.8822 - val_mean_absolute_error: 0.6815 - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.1062 - mean_absolute_error: 0.7868 - categorical_accuracy: 1.0000 - val_loss: 0.8925 - val_mean_absolute_error: 0.6940 - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0971 - mean_absolute_error: 0.7845 - categorical_accuracy: 1.0000 - val_loss: 0.8802 - val_mean_absolute_error: 0.6811 - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: 1.0951 - mean_absolute_error: 0.7843 - categorical_accuracy: 1.0000 - val_loss: 0.8846 - val_mean_absolute_error: 0.6805 - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: 1.1035 - mean_absolute_error: 0.7886 - categorical_accuracy: 1.0000 - val_loss: 0.9153 - val_mean_absolute_error: 0.7125 - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1017 - mean_absolute_error: 0.7936 - categorical_accuracy: 1.0000 - val_loss: 0.8758 - val_mean_absolute_error: 0.6793 - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0839 - mean_absolute_error: 0.7755 - categorical_accuracy: 1.0000 - val_loss: 0.8771 - val_mean_absolute_error: 0.6821 - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.1049 - mean_absolute_error: 0.7923 - categorical_accuracy: 1.0000 - val_loss: 0.8861 - val_mean_absolute_error: 0.6903 - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0802 - mean_absolute_error: 0.7788 - categorical_accuracy: 1.0000 - val_loss: 0.8787 - val_mean_absolute_error: 0.6849 - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0831 - mean_absolute_error: 0.7792 - categorical_accuracy: 1.0000 - val_loss: 0.8879 - val_mean_absolute_error: 0.6932 - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0795 - mean_absolute_error: 0.7757 - categorical_accuracy: 1.0000 - val_loss: 0.8763 - val_mean_absolute_error: 0.6834 - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0821 - mean_absolute_error: 0.7774 - categorical_accuracy: 1.0000 - val_loss: 0.8761 - val_mean_absolute_error: 0.6771 - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: 1.0804 - mean_absolute_error: 0.7776 - categorical_accuracy: 1.0000 - val_loss: 0.8872 - val_mean_absolute_error: 0.6923 - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0752 - mean_absolute_error: 0.7745 - categorical_accuracy: 1.0000 - val_loss: 0.9478 - val_mean_absolute_error: 0.7385 - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: 1.0850 - mean_absolute_error: 0.7805 - categorical_accuracy: 1.0000 - val_loss: 0.9036 - val_mean_absolute_error: 0.6920 - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0769 - mean_absolute_error: 0.7757 - categorical_accuracy: 1.0000 - val_loss: 0.8702 - val_mean_absolute_error: 0.6781 - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0767 - mean_absolute_error: 0.7767 - categorical_accuracy: 1.0000 - val_loss: 0.9018 - val_mean_absolute_error: 0.6913 - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: 1.0867 - mean_absolute_error: 0.7838 - categorical_accuracy: 1.0000 - val_loss: 0.8954 - val_mean_absolute_error: 0.6871 - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: 1.0811 - mean_absolute_error: 0.7836 - categorical_accuracy: 1.0000 - val_loss: 0.9036 - val_mean_absolute_error: 0.6922 - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0756 - mean_absolute_error: 0.7782 - categorical_accuracy: 1.0000 - val_loss: 0.8740 - val_mean_absolute_error: 0.6834 - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.1046 - mean_absolute_error: 0.7921 - categorical_accuracy: 1.0000 - val_loss: 0.8692 - val_mean_absolute_error: 0.6746 - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.1114 - mean_absolute_error: 0.7954 - categorical_accuracy: 1.0000 - val_loss: 0.8675 - val_mean_absolute_error: 0.6754 - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0696 - mean_absolute_error: 0.7765 - categorical_accuracy: 1.0000 - val_loss: 0.8805 - val_mean_absolute_error: 0.6797 - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0751 - mean_absolute_error: 0.7764 - categorical_accuracy: 1.0000 - val_loss: 0.8817 - val_mean_absolute_error: 0.6896 - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0712 - mean_absolute_error: 0.7810 - categorical_accuracy: 1.0000 - val_loss: 0.8678 - val_mean_absolute_error: 0.6778 - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0661 - mean_absolute_error: 0.7730 - categorical_accuracy: 1.0000 - val_loss: 0.8691 - val_mean_absolute_error: 0.6797 - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0702 - mean_absolute_error: 0.7754 - categorical_accuracy: 1.0000 - val_loss: 0.8689 - val_mean_absolute_error: 0.6741 - val_categorical_accuracy: 1.0000\n",
      "Epoch 140/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0676 - mean_absolute_error: 0.7764 - categorical_accuracy: 1.0000 - val_loss: 0.8671 - val_mean_absolute_error: 0.6743 - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0645 - mean_absolute_error: 0.7750 - categorical_accuracy: 1.0000 - val_loss: 0.8775 - val_mean_absolute_error: 0.6787 - val_categorical_accuracy: 1.0000\n",
      "Epoch 142/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: 1.0651 - mean_absolute_error: 0.7744 - categorical_accuracy: 1.0000 - val_loss: 0.8668 - val_mean_absolute_error: 0.6778 - val_categorical_accuracy: 1.0000\n",
      "Epoch 143/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0594 - mean_absolute_error: 0.7704 - categorical_accuracy: 1.0000 - val_loss: 0.8643 - val_mean_absolute_error: 0.6723 - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0584 - mean_absolute_error: 0.7714 - categorical_accuracy: 1.0000 - val_loss: 0.8678 - val_mean_absolute_error: 0.6738 - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: 1.0669 - mean_absolute_error: 0.7757 - categorical_accuracy: 1.0000 - val_loss: 0.8654 - val_mean_absolute_error: 0.6765 - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0644 - mean_absolute_error: 0.7772 - categorical_accuracy: 1.0000 - val_loss: 0.9116 - val_mean_absolute_error: 0.6975 - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0681 - mean_absolute_error: 0.7763 - categorical_accuracy: 1.0000 - val_loss: 0.8661 - val_mean_absolute_error: 0.6729 - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0545 - mean_absolute_error: 0.7720 - categorical_accuracy: 1.0000 - val_loss: 0.8755 - val_mean_absolute_error: 0.6787 - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0654 - mean_absolute_error: 0.7733 - categorical_accuracy: 1.0000 - val_loss: 0.8702 - val_mean_absolute_error: 0.6750 - val_categorical_accuracy: 1.0000\n",
      "Epoch 150/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0598 - mean_absolute_error: 0.7745 - categorical_accuracy: 1.0000 - val_loss: 0.8730 - val_mean_absolute_error: 0.6770 - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0593 - mean_absolute_error: 0.7716 - categorical_accuracy: 1.0000 - val_loss: 0.9263 - val_mean_absolute_error: 0.7256 - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.1200 - mean_absolute_error: 0.8015 - categorical_accuracy: 1.0000 - val_loss: 0.9347 - val_mean_absolute_error: 0.7086 - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0743 - mean_absolute_error: 0.7802 - categorical_accuracy: 1.0000 - val_loss: 0.8658 - val_mean_absolute_error: 0.6777 - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0704 - mean_absolute_error: 0.7786 - categorical_accuracy: 1.0000 - val_loss: 0.8859 - val_mean_absolute_error: 0.6844 - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0545 - mean_absolute_error: 0.7733 - categorical_accuracy: 1.0000 - val_loss: 0.9000 - val_mean_absolute_error: 0.7058 - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0626 - mean_absolute_error: 0.7743 - categorical_accuracy: 1.0000 - val_loss: 0.8679 - val_mean_absolute_error: 0.6734 - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: 1.0548 - mean_absolute_error: 0.7708 - categorical_accuracy: 1.0000 - val_loss: 0.8629 - val_mean_absolute_error: 0.6746 - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0590 - mean_absolute_error: 0.7734 - categorical_accuracy: 1.0000 - val_loss: 0.8654 - val_mean_absolute_error: 0.6771 - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: 1.0702 - mean_absolute_error: 0.7808 - categorical_accuracy: 1.0000 - val_loss: 0.8680 - val_mean_absolute_error: 0.6794 - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: 1.0669 - mean_absolute_error: 0.7750 - categorical_accuracy: 1.0000 - val_loss: 0.9221 - val_mean_absolute_error: 0.7228 - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0924 - mean_absolute_error: 0.7882 - categorical_accuracy: 1.0000 - val_loss: 0.8648 - val_mean_absolute_error: 0.6719 - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0875 - mean_absolute_error: 0.7900 - categorical_accuracy: 1.0000 - val_loss: 0.8722 - val_mean_absolute_error: 0.6764 - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0571 - mean_absolute_error: 0.7718 - categorical_accuracy: 1.0000 - val_loss: 0.8630 - val_mean_absolute_error: 0.6740 - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0510 - mean_absolute_error: 0.7711 - categorical_accuracy: 1.0000 - val_loss: 0.8802 - val_mean_absolute_error: 0.6892 - val_categorical_accuracy: 1.0000\n",
      "Epoch 165/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0573 - mean_absolute_error: 0.7745 - categorical_accuracy: 1.0000 - val_loss: 0.8875 - val_mean_absolute_error: 0.6858 - val_categorical_accuracy: 1.0000\n",
      "Epoch 166/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0562 - mean_absolute_error: 0.7765 - categorical_accuracy: 1.0000 - val_loss: 0.8757 - val_mean_absolute_error: 0.6850 - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0465 - mean_absolute_error: 0.7685 - categorical_accuracy: 1.0000 - val_loss: 0.8819 - val_mean_absolute_error: 0.6908 - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 1.0764 - mean_absolute_error: 0.7822 - categorical_accuracy: 1.0000 - val_loss: 0.8606 - val_mean_absolute_error: 0.6712 - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0585 - mean_absolute_error: 0.7721 - categorical_accuracy: 1.0000 - val_loss: 0.8703 - val_mean_absolute_error: 0.6812 - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0626 - mean_absolute_error: 0.7765 - categorical_accuracy: 1.0000 - val_loss: 0.8757 - val_mean_absolute_error: 0.6800 - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0578 - mean_absolute_error: 0.7711 - categorical_accuracy: 1.0000 - val_loss: 0.9006 - val_mean_absolute_error: 0.6933 - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 44us/sample - loss: 1.0711 - mean_absolute_error: 0.7805 - categorical_accuracy: 1.0000 - val_loss: 0.9429 - val_mean_absolute_error: 0.7374 - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 1.0844 - mean_absolute_error: 0.7874 - categorical_accuracy: 1.0000 - val_loss: 0.8618 - val_mean_absolute_error: 0.6708 - val_categorical_accuracy: 1.0000\n",
      "Epoch 174/600\n",
      "1617/1617 [==============================] - 0s 48us/sample - loss: 1.0473 - mean_absolute_error: 0.7683 - categorical_accuracy: 1.0000 - val_loss: 0.8617 - val_mean_absolute_error: 0.6732 - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0461 - mean_absolute_error: 0.7717 - categorical_accuracy: 1.0000 - val_loss: 0.8936 - val_mean_absolute_error: 0.6896 - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/600\n",
      "1617/1617 [==============================] - 0s 60us/sample - loss: 1.0530 - mean_absolute_error: 0.7708 - categorical_accuracy: 1.0000 - val_loss: 0.8691 - val_mean_absolute_error: 0.6794 - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: 1.0550 - mean_absolute_error: 0.7719 - categorical_accuracy: 1.0000 - val_loss: 0.9222 - val_mean_absolute_error: 0.7040 - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0606 - mean_absolute_error: 0.7768 - categorical_accuracy: 1.0000 - val_loss: 0.8752 - val_mean_absolute_error: 0.6785 - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0638 - mean_absolute_error: 0.7759 - categorical_accuracy: 1.0000 - val_loss: 0.8620 - val_mean_absolute_error: 0.6726 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0576 - mean_absolute_error: 0.7782 - categorical_accuracy: 1.0000 - val_loss: 0.8677 - val_mean_absolute_error: 0.6782 - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: 1.0450 - mean_absolute_error: 0.7692 - categorical_accuracy: 1.0000 - val_loss: 0.9159 - val_mean_absolute_error: 0.7177 - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0738 - mean_absolute_error: 0.7812 - categorical_accuracy: 1.0000 - val_loss: 0.8900 - val_mean_absolute_error: 0.6866 - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0587 - mean_absolute_error: 0.7720 - categorical_accuracy: 1.0000 - val_loss: 0.8983 - val_mean_absolute_error: 0.6923 - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: 1.0467 - mean_absolute_error: 0.7677 - categorical_accuracy: 1.0000 - val_loss: 0.8948 - val_mean_absolute_error: 0.6999 - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0505 - mean_absolute_error: 0.7737 - categorical_accuracy: 1.0000 - val_loss: 0.9154 - val_mean_absolute_error: 0.7015 - val_categorical_accuracy: 1.0000\n",
      "Epoch 186/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: 1.0490 - mean_absolute_error: 0.7749 - categorical_accuracy: 1.0000 - val_loss: 0.8715 - val_mean_absolute_error: 0.6768 - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/600\n",
      "1617/1617 [==============================] - 0s 58us/sample - loss: 1.0638 - mean_absolute_error: 0.7794 - categorical_accuracy: 1.0000 - val_loss: 0.9007 - val_mean_absolute_error: 0.6941 - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/600\n",
      "1617/1617 [==============================] - 0s 59us/sample - loss: 1.0582 - mean_absolute_error: 0.7756 - categorical_accuracy: 1.0000 - val_loss: 0.9261 - val_mean_absolute_error: 0.7233 - val_categorical_accuracy: 1.0000\n",
      "Epoch 189/600\n",
      "1617/1617 [==============================] - 0s 56us/sample - loss: 1.0863 - mean_absolute_error: 0.7873 - categorical_accuracy: 1.0000 - val_loss: 0.8615 - val_mean_absolute_error: 0.6716 - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/600\n",
      "1617/1617 [==============================] - 0s 58us/sample - loss: 1.0556 - mean_absolute_error: 0.7761 - categorical_accuracy: 1.0000 - val_loss: 0.8610 - val_mean_absolute_error: 0.6716 - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/600\n",
      "1617/1617 [==============================] - 0s 56us/sample - loss: 1.0600 - mean_absolute_error: 0.7780 - categorical_accuracy: 1.0000 - val_loss: 0.8670 - val_mean_absolute_error: 0.6734 - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/600\n",
      "1617/1617 [==============================] - 0s 56us/sample - loss: 1.0430 - mean_absolute_error: 0.7719 - categorical_accuracy: 1.0000 - val_loss: 0.8898 - val_mean_absolute_error: 0.6878 - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/600\n",
      "1617/1617 [==============================] - 0s 57us/sample - loss: 1.0531 - mean_absolute_error: 0.7733 - categorical_accuracy: 1.0000 - val_loss: 0.8662 - val_mean_absolute_error: 0.6765 - val_categorical_accuracy: 1.0000\n",
      "Epoch 00193: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16bbc0f29e8>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=600,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16bb8e2ee48>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    " predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7978741774807502"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6782941948950708"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(monitor='val_loss',verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1617 samples, validate on 286 samples\n",
      "Epoch 1/600\n",
      "1617/1617 [==============================] - 0s 147us/sample - loss: -13.4116 - val_loss: -20.3189\n",
      "Epoch 2/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -28.7975 - val_loss: -39.2788\n",
      "Epoch 3/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -52.6228 - val_loss: -67.7606\n",
      "Epoch 4/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -86.8777 - val_loss: -109.1721\n",
      "Epoch 5/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -138.2670 - val_loss: -171.3045\n",
      "Epoch 6/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -213.8584 - val_loss: -260.6478\n",
      "Epoch 7/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -319.5869 - val_loss: -382.8042\n",
      "Epoch 8/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -460.6067 - val_loss: -542.5081\n",
      "Epoch 9/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -642.2887 - val_loss: -744.9446\n",
      "Epoch 10/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -869.4811 - val_loss: -995.4121\n",
      "Epoch 11/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1146.8073 - val_loss: -1296.6525\n",
      "Epoch 12/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -1478.5331 - val_loss: -1654.7718\n",
      "Epoch 13/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1869.4432 - val_loss: -2073.6465\n",
      "Epoch 14/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -2322.5244 - val_loss: -2558.1020\n",
      "Epoch 15/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2842.2094 - val_loss: -3107.3274\n",
      "Epoch 16/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -3432.1054 - val_loss: -3728.9053\n",
      "Epoch 17/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -4095.3808 - val_loss: -4424.4618\n",
      "Epoch 18/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -4834.0375 - val_loss: -5196.7792\n",
      "Epoch 19/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5651.6073 - val_loss: -6048.3622\n",
      "Epoch 20/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6553.5928 - val_loss: -6982.7474\n",
      "Epoch 21/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -7537.9757 - val_loss: -8004.7078\n",
      "Epoch 22/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -8610.3518 - val_loss: -9112.4285\n",
      "Epoch 23/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -9770.8376 - val_loss: -10309.8596\n",
      "Epoch 24/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -11023.2880 - val_loss: -11594.8713\n",
      "Epoch 25/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -12367.6473 - val_loss: -12979.3881\n",
      "Epoch 26/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -13806.9749 - val_loss: -14456.3269\n",
      "Epoch 27/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -15346.2621 - val_loss: -16029.0937\n",
      "Epoch 28/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -16984.4699 - val_loss: -17702.7820\n",
      "Epoch 29/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -18723.6142 - val_loss: -19479.2492\n",
      "Epoch 30/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -20564.9935 - val_loss: -21362.1512\n",
      "Epoch 31/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -22510.4394 - val_loss: -23334.9140\n",
      "Epoch 32/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -24555.5517 - val_loss: -25424.9691\n",
      "Epoch 33/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -26709.3449 - val_loss: -27608.7844\n",
      "Epoch 34/600\n",
      "1617/1617 [==============================] - 0s 52us/sample - loss: -28969.5449 - val_loss: -29911.8225\n",
      "Epoch 35/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -31343.7807 - val_loss: -32309.8942\n",
      "Epoch 36/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -33826.0209 - val_loss: -34831.4543\n",
      "Epoch 37/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -36418.8514 - val_loss: -37460.0381\n",
      "Epoch 38/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -39127.4966 - val_loss: -40199.2227\n",
      "Epoch 39/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -41948.7593 - val_loss: -43058.1045\n",
      "Epoch 40/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -44886.1950 - val_loss: -46025.3023\n",
      "Epoch 41/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -47938.5420 - val_loss: -49116.2187\n",
      "Epoch 42/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -51110.5671 - val_loss: -52312.4829\n",
      "Epoch 43/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -54395.0306 - val_loss: -55635.2634\n",
      "Epoch 44/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -57802.7857 - val_loss: -59055.9793\n",
      "Epoch 45/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -61325.7360 - val_loss: -62625.6961\n",
      "Epoch 46/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -64969.9296 - val_loss: -66308.9681\n",
      "Epoch 47/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -68737.7907 - val_loss: -70108.7831\n",
      "Epoch 48/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -72625.3440 - val_loss: -74022.0587\n",
      "Epoch 49/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -76646.8570 - val_loss: -78039.4049\n",
      "Epoch 50/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -80780.5054 - val_loss: -82207.6736\n",
      "Epoch 51/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -85040.5912 - val_loss: -86519.2943\n",
      "Epoch 52/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -89434.8912 - val_loss: -90928.6164\n",
      "Epoch 53/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -93942.0460 - val_loss: -95468.5851\n",
      "Epoch 54/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -98586.1545 - val_loss: -100115.7325\n",
      "Epoch 55/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -103351.9137 - val_loss: -104923.1554\n",
      "Epoch 56/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -108250.8252 - val_loss: -109846.6919\n",
      "Epoch 57/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -113280.5682 - val_loss: -114895.9334\n",
      "Epoch 58/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -118445.0255 - val_loss: -120065.9063\n",
      "Epoch 59/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -123736.9199 - val_loss: -125385.9539\n",
      "Epoch 60/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -129158.3303 - val_loss: -130832.5081\n",
      "Epoch 61/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -134714.4706 - val_loss: -136397.5405\n",
      "Epoch 62/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -140402.5217 - val_loss: -142115.6025\n",
      "Epoch 63/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -146230.2333 - val_loss: -147950.8054\n",
      "Epoch 64/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -152177.0795 - val_loss: -153934.0818\n",
      "Epoch 65/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -158275.1342 - val_loss: -160044.0956\n",
      "Epoch 66/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -164504.8174 - val_loss: -166269.9002\n",
      "Epoch 67/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -170866.3406 - val_loss: -172652.3923\n",
      "Epoch 68/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -177374.5234 - val_loss: -179146.7414\n",
      "Epoch 69/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -184012.2055 - val_loss: -185823.6994\n",
      "Epoch 70/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -190794.6315 - val_loss: -192595.8618\n",
      "Epoch 71/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 33us/sample - loss: -197708.5621 - val_loss: -199571.7425\n",
      "Epoch 72/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -204781.6842 - val_loss: -206589.1886\n",
      "Epoch 73/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -211968.4723 - val_loss: -213810.5032\n",
      "Epoch 74/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -219307.7022 - val_loss: -221173.3032\n",
      "Epoch 75/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -226796.7838 - val_loss: -228662.6112\n",
      "Epoch 76/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -234423.5356 - val_loss: -236283.4453\n",
      "Epoch 77/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -242190.7974 - val_loss: -244068.6745\n",
      "Epoch 78/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -250111.5560 - val_loss: -251951.2188\n",
      "Epoch 79/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -258162.6577 - val_loss: -260021.3615\n",
      "Epoch 80/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -266379.2276 - val_loss: -268251.7491\n",
      "Epoch 81/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -274731.8228 - val_loss: -276608.2528\n",
      "Epoch 82/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -283233.7649 - val_loss: -285076.7791\n",
      "Epoch 83/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -291873.5086 - val_loss: -293756.5809\n",
      "Epoch 84/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -300670.5786 - val_loss: -302566.6506\n",
      "Epoch 85/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -309611.6694 - val_loss: -311482.8066\n",
      "Epoch 86/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -318700.6150 - val_loss: -320568.0780\n",
      "Epoch 87/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -327955.8930 - val_loss: -329789.3433\n",
      "Epoch 88/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -337346.2134 - val_loss: -339209.6842\n",
      "Epoch 89/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -346901.5767 - val_loss: -348744.5894\n",
      "Epoch 90/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -356603.6619 - val_loss: -358457.8593\n",
      "Epoch 91/600\n",
      "1617/1617 [==============================] - 0s 55us/sample - loss: -366473.6590 - val_loss: -368296.0000\n",
      "Epoch 92/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -376481.0470 - val_loss: -378297.4950\n",
      "Epoch 93/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -386643.9757 - val_loss: -388456.1823\n",
      "Epoch 94/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -396964.8851 - val_loss: -398760.5249\n",
      "Epoch 95/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -407437.9760 - val_loss: -409220.4102\n",
      "Epoch 96/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -418067.6002 - val_loss: -419866.1254\n",
      "Epoch 97/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -428864.6145 - val_loss: -430595.4764\n",
      "Epoch 98/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -439809.1891 - val_loss: -441540.3824\n",
      "Epoch 99/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -450911.2379 - val_loss: -452635.4102\n",
      "Epoch 100/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -462170.9003 - val_loss: -463909.1447\n",
      "Epoch 101/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -473625.3011 - val_loss: -475278.7968\n",
      "Epoch 102/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -485213.5666 - val_loss: -486865.2753\n",
      "Epoch 103/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -496970.9399 - val_loss: -498614.9419\n",
      "Epoch 104/600\n",
      "1617/1617 [==============================] - 0s 52us/sample - loss: -508896.4414 - val_loss: -510478.2679\n",
      "Epoch 105/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -520957.1165 - val_loss: -522561.6517\n",
      "Epoch 106/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -533212.9362 - val_loss: -534776.1849\n",
      "Epoch 107/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -545637.0738 - val_loss: -547123.0179\n",
      "Epoch 108/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -558215.0288 - val_loss: -559675.4209\n",
      "Epoch 109/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -570961.7406 - val_loss: -572398.3715\n",
      "Epoch 110/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -583880.3306 - val_loss: -585281.9388\n",
      "Epoch 111/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -596951.0682 - val_loss: -598365.9712\n",
      "Epoch 112/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -610209.0451 - val_loss: -611602.1320\n",
      "Epoch 113/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -623624.9747 - val_loss: -624935.6525\n",
      "Epoch 114/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -637183.0315 - val_loss: -638564.0144\n",
      "Epoch 115/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -650948.3472 - val_loss: -652229.4143\n",
      "Epoch 116/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -664870.2525 - val_loss: -666170.9375\n",
      "Epoch 117/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -678965.7741 - val_loss: -680210.2810\n",
      "Epoch 118/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -693221.0325 - val_loss: -694416.3405\n",
      "Epoch 119/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -707668.7444 - val_loss: -708831.0197\n",
      "Epoch 120/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -722282.2256 - val_loss: -723348.3282\n",
      "Epoch 121/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -737057.8294 - val_loss: -738111.9458\n",
      "Epoch 122/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -752035.1004 - val_loss: -753026.7338\n",
      "Epoch 123/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -767171.0076 - val_loss: -768183.4698\n",
      "Epoch 124/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -782495.4347 - val_loss: -783440.7566\n",
      "Epoch 125/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -798009.1914 - val_loss: -798842.4751\n",
      "Epoch 126/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -813682.6696 - val_loss: -814560.4563\n",
      "Epoch 127/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -829571.3294 - val_loss: -830338.8108\n",
      "Epoch 128/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -845611.4293 - val_loss: -846342.0087\n",
      "Epoch 129/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -861823.9959 - val_loss: -862503.3728\n",
      "Epoch 130/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -878220.9659 - val_loss: -878854.9209\n",
      "Epoch 131/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -894810.0044 - val_loss: -895389.7823\n",
      "Epoch 132/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -911598.4518 - val_loss: -912073.6123\n",
      "Epoch 133/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -928533.8094 - val_loss: -928994.8046\n",
      "Epoch 134/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -945693.3564 - val_loss: -946112.3020\n",
      "Epoch 135/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -963042.8313 - val_loss: -963294.1792\n",
      "Epoch 136/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -980548.2613 - val_loss: -980815.0074\n",
      "Epoch 137/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -998256.4970 - val_loss: -998509.2863\n",
      "Epoch 138/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -1016157.9082 - val_loss: -1016398.4510\n",
      "Epoch 139/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1034272.7296 - val_loss: -1034327.0122\n",
      "Epoch 140/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -1052522.8376 - val_loss: -1052550.6923\n",
      "Epoch 141/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1070991.4644 - val_loss: -1070893.2579\n",
      "Epoch 142/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1089623.2406 - val_loss: -1089490.4974\n",
      "Epoch 143/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1108477.8258 - val_loss: -1108282.4047\n",
      "Epoch 144/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1127510.1216 - val_loss: -1127269.0559\n",
      "Epoch 145/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -1146741.0565 - val_loss: -1146440.6871\n",
      "Epoch 146/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -1166155.2038 - val_loss: -1165750.1906\n",
      "Epoch 147/600\n",
      "1617/1617 [==============================] - 0s 26us/sample - loss: -1185760.2862 - val_loss: -1185258.3322\n",
      "Epoch 148/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1205558.7417 - val_loss: -1205009.5114\n",
      "Epoch 149/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -1225613.9569 - val_loss: -1224922.1643\n",
      "Epoch 150/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1245814.2836 - val_loss: -1245082.1530\n",
      "Epoch 151/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1266214.9900 - val_loss: -1265403.9274\n",
      "Epoch 152/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -1286829.7979 - val_loss: -1285936.9205\n",
      "Epoch 153/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1307631.5682 - val_loss: -1306633.6678\n",
      "Epoch 154/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -1328621.1024 - val_loss: -1327603.7107\n",
      "Epoch 155/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1349843.6818 - val_loss: -1348659.6372\n",
      "Epoch 156/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1371218.2117 - val_loss: -1370005.7990\n",
      "Epoch 157/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1392833.1250 - val_loss: -1391537.7054\n",
      "Epoch 158/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -1414642.3426 - val_loss: -1413250.9432\n",
      "Epoch 159/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1436669.1740 - val_loss: -1435110.4021\n",
      "Epoch 160/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1458847.0960 - val_loss: -1457262.5122\n",
      "Epoch 161/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -1481278.5406 - val_loss: -1479607.1372\n",
      "Epoch 162/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1503899.8980 - val_loss: -1502137.5892\n",
      "Epoch 163/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -1526775.5813 - val_loss: -1524840.1180\n",
      "Epoch 164/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1549801.6601 - val_loss: -1547870.2334\n",
      "Epoch 165/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1573130.4462 - val_loss: -1570996.4344\n",
      "Epoch 166/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1596605.1818 - val_loss: -1594420.8269\n",
      "Epoch 167/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1620290.3605 - val_loss: -1618036.3348\n",
      "Epoch 168/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1644155.0890 - val_loss: -1641884.8330\n",
      "Epoch 169/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1668298.0438 - val_loss: -1665719.0227\n",
      "Epoch 170/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -1692572.7019 - val_loss: -1690019.1530\n",
      "Epoch 171/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -1717097.4502 - val_loss: -1714378.3969\n",
      "Epoch 172/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1741844.8388 - val_loss: -1739018.1023\n",
      "Epoch 173/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -1766777.1440 - val_loss: -1763856.1626\n",
      "Epoch 174/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -1791935.4165 - val_loss: -1788928.8147\n",
      "Epoch 175/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -1817318.5670 - val_loss: -1814117.1888\n",
      "Epoch 176/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -1842897.6320 - val_loss: -1839655.6600\n",
      "Epoch 177/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -1868732.7240 - val_loss: -1865298.1993\n",
      "Epoch 178/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1894768.9287 - val_loss: -1891258.6897\n",
      "Epoch 179/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1921003.2627 - val_loss: -1917350.5323\n",
      "Epoch 180/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -1947466.7236 - val_loss: -1943694.3593\n",
      "Epoch 181/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -1974168.6096 - val_loss: -1970396.6241\n",
      "Epoch 182/600\n",
      "1617/1617 [==============================] - 0s 64us/sample - loss: -2001121.7068 - val_loss: -1997136.9869\n",
      "Epoch 183/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2028284.1490 - val_loss: -2024090.8654\n",
      "Epoch 184/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2055634.6050 - val_loss: -2051394.8706\n",
      "Epoch 185/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2083245.2964 - val_loss: -2078910.7587\n",
      "Epoch 186/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -2111101.5527 - val_loss: -2106512.2596\n",
      "Epoch 187/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2139137.8184 - val_loss: -2134440.3759\n",
      "Epoch 188/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2167407.6648 - val_loss: -2162551.6932\n",
      "Epoch 189/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2195908.2025 - val_loss: -2190978.8610\n",
      "Epoch 190/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2224660.5918 - val_loss: -2219505.3304\n",
      "Epoch 191/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -2253565.6391 - val_loss: -2248381.3383\n",
      "Epoch 192/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2282772.2035 - val_loss: -2277407.7710\n",
      "Epoch 193/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -2312183.5762 - val_loss: -2306626.9965\n",
      "Epoch 194/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -2341811.1721 - val_loss: -2336152.4073\n",
      "Epoch 195/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -2371702.6739 - val_loss: -2365826.4738\n",
      "Epoch 196/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2401790.8636 - val_loss: -2395755.1556\n",
      "Epoch 197/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -2432105.3568 - val_loss: -2426091.2850\n",
      "Epoch 198/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2462735.1387 - val_loss: -2456374.1346\n",
      "Epoch 199/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -2493520.8992 - val_loss: -2487083.3741\n",
      "Epoch 200/600\n",
      "1617/1617 [==============================] - 0s 55us/sample - loss: -2524595.4706 - val_loss: -2518024.2885\n",
      "Epoch 201/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -2555918.8582 - val_loss: -2549133.4336\n",
      "Epoch 202/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -2587429.9332 - val_loss: -2580481.8339\n",
      "Epoch 203/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -2619176.7893 - val_loss: -2612098.4983\n",
      "Epoch 204/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -2651198.6523 - val_loss: -2643838.0035\n",
      "Epoch 205/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -2683408.8647 - val_loss: -2676082.7850\n",
      "Epoch 206/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 47us/sample - loss: -2715921.9583 - val_loss: -2708390.6573\n",
      "Epoch 207/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -2748651.7517 - val_loss: -2740899.1556\n",
      "Epoch 208/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -2781583.1829 - val_loss: -2773767.5787\n",
      "Epoch 209/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: -2814824.7313 - val_loss: -2806682.9965\n",
      "Epoch 210/600\n",
      "1617/1617 [==============================] - 0s 50us/sample - loss: -2848287.4814 - val_loss: -2839990.1713\n",
      "Epoch 211/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -2881964.9810 - val_loss: -2873497.6626\n",
      "Epoch 212/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -2915858.2287 - val_loss: -2907273.4860\n",
      "Epoch 213/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -2950035.0700 - val_loss: -2941144.5944\n",
      "Epoch 214/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: -2984415.0365 - val_loss: -2975413.6224\n",
      "Epoch 215/600\n",
      "1617/1617 [==============================] - 0s 72us/sample - loss: -3019087.3861 - val_loss: -3009854.0122\n",
      "Epoch 216/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -3053977.6459 - val_loss: -3044756.7010\n",
      "Epoch 217/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3089197.1058 - val_loss: -3079379.4633\n",
      "Epoch 218/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -3124557.7645 - val_loss: -3114871.5280\n",
      "Epoch 219/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -3160304.5025 - val_loss: -3150316.1311\n",
      "Epoch 220/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -3196147.3191 - val_loss: -3186166.7850\n",
      "Epoch 221/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -3232297.3596 - val_loss: -3221911.8077\n",
      "Epoch 222/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -3268717.5615 - val_loss: -3258062.9930\n",
      "Epoch 223/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -3305360.5642 - val_loss: -3294435.9476\n",
      "Epoch 224/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3342248.1767 - val_loss: -3331243.1643\n",
      "Epoch 225/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3379378.2781 - val_loss: -3368289.6329\n",
      "Epoch 226/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3416824.4618 - val_loss: -3405526.3252\n",
      "Epoch 227/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3454530.6708 - val_loss: -3442944.9266\n",
      "Epoch 228/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3492483.5737 - val_loss: -3480582.8969\n",
      "Epoch 229/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3530563.7545 - val_loss: -3518713.9353\n",
      "Epoch 230/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3568994.7157 - val_loss: -3556939.7080\n",
      "Epoch 231/600\n",
      "1617/1617 [==============================] - 0s 57us/sample - loss: -3607734.8813 - val_loss: -3595190.4143\n",
      "Epoch 232/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -3646635.8800 - val_loss: -3634187.8566\n",
      "Epoch 233/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -3685900.6985 - val_loss: -3673178.7815\n",
      "Epoch 234/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3725349.5702 - val_loss: -3712486.9266\n",
      "Epoch 235/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3765116.7879 - val_loss: -3751821.8986\n",
      "Epoch 236/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3805080.9162 - val_loss: -3791632.9056\n",
      "Epoch 237/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3845377.5932 - val_loss: -3831751.7657\n",
      "Epoch 238/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -3885912.5430 - val_loss: -3872226.6031\n",
      "Epoch 239/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -3926728.0037 - val_loss: -3912644.3671\n",
      "Epoch 240/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -3967784.4598 - val_loss: -3953442.2710\n",
      "Epoch 241/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -4009135.9661 - val_loss: -3994429.2517\n",
      "Epoch 242/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -4050703.4334 - val_loss: -4035827.8899\n",
      "Epoch 243/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -4092532.1647 - val_loss: -4077484.6154\n",
      "Epoch 244/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -4134701.6207 - val_loss: -4119266.1853\n",
      "Epoch 245/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4177068.4630 - val_loss: -4161478.9388\n",
      "Epoch 246/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -4219735.6993 - val_loss: -4203981.9091\n",
      "Epoch 247/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -4262647.9447 - val_loss: -4246607.5699\n",
      "Epoch 248/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -4305878.6685 - val_loss: -4289485.7273\n",
      "Epoch 249/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -4349372.6657 - val_loss: -4332822.7657\n",
      "Epoch 250/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -4393195.1945 - val_loss: -4376350.9860\n",
      "Epoch 251/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -4437280.6942 - val_loss: -4420080.1136\n",
      "Epoch 252/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -4481584.5402 - val_loss: -4464106.6434\n",
      "Epoch 253/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -4526109.4561 - val_loss: -4508568.2797\n",
      "Epoch 254/600\n",
      "1617/1617 [==============================] - 0s 26us/sample - loss: -4570941.6088 - val_loss: -4553187.6119\n",
      "Epoch 255/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -4616111.5683 - val_loss: -4598019.5420\n",
      "Epoch 256/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -4661478.4196 - val_loss: -4643268.0070\n",
      "Epoch 257/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -4707142.9536 - val_loss: -4688703.1049\n",
      "Epoch 258/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -4753137.2489 - val_loss: -4734201.7098\n",
      "Epoch 259/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -4799362.1082 - val_loss: -4780264.2517\n",
      "Epoch 260/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -4845879.9870 - val_loss: -4826490.5350\n",
      "Epoch 261/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -4892719.2811 - val_loss: -4873003.2587\n",
      "Epoch 262/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -4939769.5257 - val_loss: -4919755.6573\n",
      "Epoch 263/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -4987127.3565 - val_loss: -4967074.3671\n",
      "Epoch 264/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -5034867.4716 - val_loss: -5014247.2972\n",
      "Epoch 265/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -5082720.2007 - val_loss: -5062093.9685\n",
      "Epoch 266/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -5130986.5269 - val_loss: -5109831.9545\n",
      "Epoch 267/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -5179504.8472 - val_loss: -5158108.9021\n",
      "Epoch 268/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -5228304.3587 - val_loss: -5206610.3287\n",
      "Epoch 269/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5277420.8194 - val_loss: -5255310.3951\n",
      "Epoch 270/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5326796.6673 - val_loss: -5304591.7797\n",
      "Epoch 271/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5376544.7492 - val_loss: -5353793.9371\n",
      "Epoch 272/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5426468.1166 - val_loss: -5403490.5524\n",
      "Epoch 273/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5476715.2628 - val_loss: -5453431.8182\n",
      "Epoch 274/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5527273.5615 - val_loss: -5503747.1364\n",
      "Epoch 275/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5578081.9344 - val_loss: -5554303.0909\n",
      "Epoch 276/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5629233.4567 - val_loss: -5605107.0769\n",
      "Epoch 277/600\n",
      "1617/1617 [==============================] - ETA: 0s - loss: -5613662.50 - 0s 27us/sample - loss: -5680621.3105 - val_loss: -5656237.6993\n",
      "Epoch 278/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5732307.6784 - val_loss: -5707676.3951\n",
      "Epoch 279/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5784362.7965 - val_loss: -5759301.7762\n",
      "Epoch 280/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5836615.2934 - val_loss: -5811364.2308\n",
      "Epoch 281/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5889265.4162 - val_loss: -5863484.2028\n",
      "Epoch 282/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5942164.8472 - val_loss: -5916171.1224\n",
      "Epoch 283/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -5995336.4286 - val_loss: -5968985.4161\n",
      "Epoch 284/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6048768.2703 - val_loss: -6022193.3811\n",
      "Epoch 285/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6102569.0516 - val_loss: -6075648.0000\n",
      "Epoch 286/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -6156599.6957 - val_loss: -6129411.4930\n",
      "Epoch 287/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6210984.7443 - val_loss: -6183234.9895\n",
      "Epoch 288/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6265650.0884 - val_loss: -6237803.6469\n",
      "Epoch 289/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6320702.2390 - val_loss: -6292383.6224\n",
      "Epoch 290/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6375954.0093 - val_loss: -6347401.0524\n",
      "Epoch 291/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6431596.4527 - val_loss: -6402502.6748\n",
      "Epoch 292/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -6487457.9991 - val_loss: -6458357.3147\n",
      "Epoch 293/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -6543728.1101 - val_loss: -6514113.8706\n",
      "Epoch 294/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6600260.5782 - val_loss: -6570187.2448\n",
      "Epoch 295/600\n",
      "1617/1617 [==============================] - 0s 26us/sample - loss: -6657053.7650 - val_loss: -6626615.8252\n",
      "Epoch 296/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6714147.8027 - val_loss: -6683447.5909\n",
      "Epoch 297/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6771541.2613 - val_loss: -6740454.8392\n",
      "Epoch 298/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6829234.6589 - val_loss: -6797899.8601\n",
      "Epoch 299/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6887255.4131 - val_loss: -6855514.6469\n",
      "Epoch 300/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -6945610.5328 - val_loss: -6913444.6818\n",
      "Epoch 301/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -7004178.9567 - val_loss: -6971888.2797\n",
      "Epoch 302/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -7063235.8454 - val_loss: -7030122.6643\n",
      "Epoch 303/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -7122335.8924 - val_loss: -7089202.3706\n",
      "Epoch 304/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -7182083.1722 - val_loss: -7148334.5385\n",
      "Epoch 305/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -7241900.7245 - val_loss: -7208175.7098\n",
      "Epoch 306/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -7302235.5761 - val_loss: -7267836.0245\n",
      "Epoch 307/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -7362728.1942 - val_loss: -7327888.0944\n",
      "Epoch 308/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -7423566.7118 - val_loss: -7388553.6329\n",
      "Epoch 309/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -7484795.4375 - val_loss: -7449166.5420\n",
      "Epoch 310/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -7546246.0955 - val_loss: -7510353.6888\n",
      "Epoch 311/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -7608095.7310 - val_loss: -7571606.8322\n",
      "Epoch 312/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -7670108.0445 - val_loss: -7633709.2727\n",
      "Epoch 313/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -7732593.8330 - val_loss: -7695697.4056\n",
      "Epoch 314/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -7795315.4447 - val_loss: -7757671.7762\n",
      "Epoch 315/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -7858405.3819 - val_loss: -7820355.4895\n",
      "Epoch 316/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -7921826.4227 - val_loss: -7883452.1154\n",
      "Epoch 317/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -7985527.9041 - val_loss: -7946863.4895\n",
      "Epoch 318/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8049668.9431 - val_loss: -8010548.3077\n",
      "Epoch 319/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8114089.6673 - val_loss: -8074557.9231\n",
      "Epoch 320/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8178819.1194 - val_loss: -8139014.7587\n",
      "Epoch 321/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8243952.4335 - val_loss: -8203629.9196\n",
      "Epoch 322/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -8309391.7044 - val_loss: -8268507.8986\n",
      "Epoch 323/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -8375131.7304 - val_loss: -8333875.1399\n",
      "Epoch 324/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8441176.7922 - val_loss: -8399431.8077\n",
      "Epoch 325/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8507461.7001 - val_loss: -8465447.4266\n",
      "Epoch 326/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8574156.4954 - val_loss: -8531631.7343\n",
      "Epoch 327/600\n",
      "1617/1617 [==============================] - 0s 26us/sample - loss: -8641198.6240 - val_loss: -8598114.2797\n",
      "Epoch 328/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8708532.6809 - val_loss: -8665041.7657\n",
      "Epoch 329/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8776132.0594 - val_loss: -8732241.0420\n",
      "Epoch 330/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8844059.9539 - val_loss: -8800031.2448\n",
      "Epoch 331/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8912355.7254 - val_loss: -8867959.9021\n",
      "Epoch 332/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -8981081.1676 - val_loss: -8935653.5245\n",
      "Epoch 333/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9049981.0977 - val_loss: -9004426.6224\n",
      "Epoch 334/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9119338.5683 - val_loss: -9073484.4266\n",
      "Epoch 335/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9188949.5906 - val_loss: -9142491.0979\n",
      "Epoch 336/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -9258927.4694 - val_loss: -9212085.9510\n",
      "Epoch 337/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -9329283.4045 - val_loss: -9281841.2448\n",
      "Epoch 338/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9399882.7904 - val_loss: -9351958.4755\n",
      "Epoch 339/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9470806.3429 - val_loss: -9422873.8671\n",
      "Epoch 340/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9542154.9907 - val_loss: -9493544.4056\n",
      "Epoch 341/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -9613836.5022 - val_loss: -9564500.5455\n",
      "Epoch 342/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9685872.2362 - val_loss: -9636148.1189\n",
      "Epoch 343/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9758247.1874 - val_loss: -9708305.8601\n",
      "Epoch 344/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9831045.1348 - val_loss: -9780297.6713\n",
      "Epoch 345/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9904076.6883 - val_loss: -9853159.3497\n",
      "Epoch 346/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -9977506.6228 - val_loss: -9925842.7203\n",
      "Epoch 347/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10051262.6988 - val_loss: -9999110.3706\n",
      "Epoch 348/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10125340.1330 - val_loss: -10072734.8741\n",
      "Epoch 349/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10199816.0334 - val_loss: -10146619.1888\n",
      "Epoch 350/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10274625.3754 - val_loss: -10220881.7063\n",
      "Epoch 351/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10349822.7712 - val_loss: -10295842.3776\n",
      "Epoch 352/600\n",
      "1617/1617 [==============================] - 0s 26us/sample - loss: -10425374.5974 - val_loss: -10370817.0979\n",
      "Epoch 353/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10501171.5955 - val_loss: -10446107.9860\n",
      "Epoch 354/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10577291.6333 - val_loss: -10521869.1399\n",
      "Epoch 355/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10653864.9215 - val_loss: -10597726.6573\n",
      "Epoch 356/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10730581.3228 - val_loss: -10673987.4056\n",
      "Epoch 357/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10807768.5751 - val_loss: -10750731.3916\n",
      "Epoch 358/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -10885314.6889 - val_loss: -10827842.9161\n",
      "Epoch 359/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -10963251.4638 - val_loss: -10905288.6643\n",
      "Epoch 360/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -11041482.8980 - val_loss: -10983082.5245\n",
      "Epoch 361/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -11120159.2263 - val_loss: -11061034.0350\n",
      "Epoch 362/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -11199166.6710 - val_loss: -11139389.8042\n",
      "Epoch 363/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -11278478.7384 - val_loss: -11218296.3566\n",
      "Epoch 364/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -11358209.1991 - val_loss: -11297514.8252\n",
      "Epoch 365/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -11438256.2870 - val_loss: -11376988.6853\n",
      "Epoch 366/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -11518631.9784 - val_loss: -11456751.7273\n",
      "Epoch 367/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -11599381.4440 - val_loss: -11537115.4825\n",
      "Epoch 368/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -11680584.3309 - val_loss: -11617800.3007\n",
      "Epoch 369/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -11762084.3525 - val_loss: -11698875.0490\n",
      "Epoch 370/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -11844001.3346 - val_loss: -11779896.8601\n",
      "Epoch 371/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -11926132.5943 - val_loss: -11861578.5664\n",
      "Epoch 372/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -12008811.5213 - val_loss: -11943597.2448\n",
      "Epoch 373/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -12091760.9147 - val_loss: -12026348.8881\n",
      "Epoch 374/600\n",
      "1617/1617 [==============================] - 0s 27us/sample - loss: -12175138.5727 - val_loss: -12108929.6084\n",
      "Epoch 375/600\n",
      "1617/1617 [==============================] - 0s 69us/sample - loss: -12258767.6883 - val_loss: -12191938.0909\n",
      "Epoch 376/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -12342744.1336 - val_loss: -12275554.8601\n",
      "Epoch 377/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -12427167.2344 - val_loss: -12359225.7622\n",
      "Epoch 378/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -12511852.3222 - val_loss: -12443547.6573\n",
      "Epoch 379/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -12596997.2907 - val_loss: -12527968.6853\n",
      "Epoch 380/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -12682515.2752 - val_loss: -12612879.2937\n",
      "Epoch 381/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -12768472.0835 - val_loss: -12698312.2028\n",
      "Epoch 382/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -12854738.5003 - val_loss: -12784017.6783\n",
      "Epoch 383/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -12941355.9759 - val_loss: -12870189.1678\n",
      "Epoch 384/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -13028392.6308 - val_loss: -12956701.6643\n",
      "Epoch 385/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -13115850.5393 - val_loss: -13043414.9650\n",
      "Epoch 386/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -13203552.1515 - val_loss: -13130463.6643\n",
      "Epoch 387/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -13291686.7137 - val_loss: -13217835.8601\n",
      "Epoch 388/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -13380173.7817 - val_loss: -13305877.1608\n",
      "Epoch 389/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -13469026.8565 - val_loss: -13394345.9091\n",
      "Epoch 390/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -13558327.3884 - val_loss: -13482851.0699\n",
      "Epoch 391/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -13647894.2876 - val_loss: -13571816.0629\n",
      "Epoch 392/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -13737923.5925 - val_loss: -13661434.3287\n",
      "Epoch 393/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -13828376.5275 - val_loss: -13750991.0559\n",
      "Epoch 394/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -13919095.9703 - val_loss: -13840857.4965\n",
      "Epoch 395/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -14010142.3847 - val_loss: -13931820.7622\n",
      "Epoch 396/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14101725.9666 - val_loss: -14022441.3077\n",
      "Epoch 397/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -14193676.5572 - val_loss: -14113345.5315\n",
      "Epoch 398/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -14285822.5269 - val_loss: -14205296.3776\n",
      "Epoch 399/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -14378585.4100 - val_loss: -14297339.6503\n",
      "Epoch 400/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -14471718.4873 - val_loss: -14389800.4685\n",
      "Epoch 401/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14564977.5312 - val_loss: -14483056.5594\n",
      "Epoch 402/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -14658932.2715 - val_loss: -14575788.0979\n",
      "Epoch 403/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -14752964.6933 - val_loss: -14669280.1189\n",
      "Epoch 404/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -14847655.1682 - val_loss: -14763040.5175\n",
      "Epoch 405/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -14942512.6481 - val_loss: -14857667.8881\n",
      "Epoch 406/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -15037981.9777 - val_loss: -14951859.0699\n",
      "Epoch 407/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -15133727.3370 - val_loss: -15047026.8601\n",
      "Epoch 408/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -15229944.0000 - val_loss: -15142767.0559\n",
      "Epoch 409/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -15326453.5937 - val_loss: -15238789.7203\n",
      "Epoch 410/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -15423244.9524 - val_loss: -15335071.3077\n",
      "Epoch 411/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -15520627.6030 - val_loss: -15431700.5664\n",
      "Epoch 412/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -15618350.5690 - val_loss: -15528499.0070\n",
      "Epoch 413/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -15716412.9839 - val_loss: -15626114.4545\n",
      "Epoch 414/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -15814924.3241 - val_loss: -15723831.1888\n",
      "Epoch 415/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -15913816.0031 - val_loss: -15821705.5245\n",
      "Epoch 416/600\n",
      "1617/1617 [==============================] - 0s 50us/sample - loss: -16012901.6883 - val_loss: -15920867.7343\n",
      "Epoch 417/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -16112784.9839 - val_loss: -16019147.5105\n",
      "Epoch 418/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -16212636.7168 - val_loss: -16119049.2238\n",
      "Epoch 419/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -16313151.3624 - val_loss: -16218973.8112\n",
      "Epoch 420/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -16414005.6450 - val_loss: -16319191.7343\n",
      "Epoch 421/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -16515295.3692 - val_loss: -16419498.8601\n",
      "Epoch 422/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -16616835.5022 - val_loss: -16520766.4196\n",
      "Epoch 423/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -16719022.9944 - val_loss: -16621671.8462\n",
      "Epoch 424/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -16821303.9208 - val_loss: -16723828.4196\n",
      "Epoch 425/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -16924268.4539 - val_loss: -16825508.1538\n",
      "Epoch 426/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -17027488.7792 - val_loss: -16928035.8741\n",
      "Epoch 427/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -17131257.4651 - val_loss: -17030796.4755\n",
      "Epoch 428/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -17235162.8868 - val_loss: -17134602.3636\n",
      "Epoch 429/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -17339811.9926 - val_loss: -17238035.0350\n",
      "Epoch 430/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -17444560.7693 - val_loss: -17342047.4406\n",
      "Epoch 431/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -17549892.2832 - val_loss: -17446714.4615\n",
      "Epoch 432/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -17655773.6481 - val_loss: -17551469.1888\n",
      "Epoch 433/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -17761781.1861 - val_loss: -17656856.1958\n",
      "Epoch 434/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -17868304.8101 - val_loss: -17763001.9580\n",
      "Epoch 435/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -17975269.0068 - val_loss: -17869477.9860\n",
      "Epoch 436/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -18082689.6549 - val_loss: -17975932.3427\n",
      "Epoch 437/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -18190464.4465 - val_loss: -18082909.2168\n",
      "Epoch 438/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -18298560.2041 - val_loss: -18190446.2657\n",
      "Epoch 439/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -18407153.8850 - val_loss: -18298043.9580\n",
      "Epoch 440/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -18515954.4774 - val_loss: -18406371.3986\n",
      "Epoch 441/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -18625544.3265 - val_loss: -18514612.9790\n",
      "Epoch 442/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -18735200.8466 - val_loss: -18623728.0140\n",
      "Epoch 443/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -18845240.5628 - val_loss: -18733299.3497\n",
      "Epoch 444/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -18955813.5436 - val_loss: -18843007.4965\n",
      "Epoch 445/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -19066851.6895 - val_loss: -18952885.9021\n",
      "Epoch 446/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -19178145.5572 - val_loss: -19063953.4545\n",
      "Epoch 447/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -19289939.5461 - val_loss: -19175062.8671\n",
      "Epoch 448/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -19402316.7137 - val_loss: -19286294.3357\n",
      "Epoch 449/600\n",
      "1617/1617 [==============================] - 0s 54us/sample - loss: -19514934.5059 - val_loss: -19398158.2937\n",
      "Epoch 450/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -19628174.0322 - val_loss: -19510260.4895\n",
      "Epoch 451/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -19741855.8417 - val_loss: -19623270.2238\n",
      "Epoch 452/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -19855944.5467 - val_loss: -19736552.4615\n",
      "Epoch 453/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -19970190.4329 - val_loss: -19850330.6294\n",
      "Epoch 454/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -20085055.3531 - val_loss: -19964135.2308\n",
      "Epoch 455/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -20200217.5993 - val_loss: -20078832.3357\n",
      "Epoch 456/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -20315819.4286 - val_loss: -20193557.0909\n",
      "Epoch 457/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -20431859.5275 - val_loss: -20308382.7413\n",
      "Epoch 458/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -20548354.8596 - val_loss: -20424052.8811\n",
      "Epoch 459/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -20665158.6456 - val_loss: -20540379.7622\n",
      "Epoch 460/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -20782580.2239 - val_loss: -20656833.7622\n",
      "Epoch 461/600\n",
      "1617/1617 [==============================] - 0s 56us/sample - loss: -20900567.7205 - val_loss: -20773495.8881\n",
      "Epoch 462/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -21018681.3519 - val_loss: -20891193.4965\n",
      "Epoch 463/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -21137445.8169 - val_loss: -21009006.5035\n",
      "Epoch 464/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -21256660.3859 - val_loss: -21126830.9790\n",
      "Epoch 465/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -21376134.5380 - val_loss: -21246153.6084\n",
      "Epoch 466/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -21496311.5077 - val_loss: -21365099.7622\n",
      "Epoch 467/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -21616668.9623 - val_loss: -21485171.9860\n",
      "Epoch 468/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -21737564.9821 - val_loss: -21604903.7762\n",
      "Epoch 469/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -21858573.8207 - val_loss: -21725479.7343\n",
      "Epoch 470/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -21980301.2022 - val_loss: -21845639.2448\n",
      "Epoch 471/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -22102126.7730 - val_loss: -21967192.5455\n",
      "Epoch 472/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 40us/sample - loss: -22224597.6537 - val_loss: -22088767.4825\n",
      "Epoch 473/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -22347626.7409 - val_loss: -22210597.0769\n",
      "Epoch 474/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -22470836.5356 - val_loss: -22333312.9371\n",
      "Epoch 475/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -22594784.0025 - val_loss: -22456016.1399\n",
      "Epoch 476/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -22718955.1676 - val_loss: -22579360.4895\n",
      "Epoch 477/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -22843695.0785 - val_loss: -22703071.6503\n",
      "Epoch 478/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -22968706.3117 - val_loss: -22827338.9371\n",
      "Epoch 479/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -23094397.9951 - val_loss: -22951817.1329\n",
      "Epoch 480/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -23220300.2597 - val_loss: -23077588.3497\n",
      "Epoch 481/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -23346918.7285 - val_loss: -23202713.6643\n",
      "Epoch 482/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -23473702.0767 - val_loss: -23328521.2448\n",
      "Epoch 483/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -23600946.9536 - val_loss: -23454752.9650\n",
      "Epoch 484/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -23728527.5993 - val_loss: -23582090.7413\n",
      "Epoch 485/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -23856761.1515 - val_loss: -23709260.6154\n",
      "Epoch 486/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -23985365.5485 - val_loss: -23836713.4825\n",
      "Epoch 487/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -24114411.3210 - val_loss: -23964386.7273\n",
      "Epoch 488/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -24244063.7341 - val_loss: -24093299.5245\n",
      "Epoch 489/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -24374002.5380 - val_loss: -24222906.6154\n",
      "Epoch 490/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -24504731.6772 - val_loss: -24351745.1049\n",
      "Epoch 491/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -24635421.4768 - val_loss: -24482541.3007\n",
      "Epoch 492/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -24767006.8200 - val_loss: -24612795.8322\n",
      "Epoch 493/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -24898738.3810 - val_loss: -24743508.4196\n",
      "Epoch 494/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -25031046.0223 - val_loss: -24874811.2028\n",
      "Epoch 495/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: -25163874.1818 - val_loss: -25006792.8671\n",
      "Epoch 496/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -25297205.1453 - val_loss: -25138931.0629\n",
      "Epoch 497/600\n",
      "1617/1617 [==============================] - 0s 48us/sample - loss: -25430553.8417 - val_loss: -25272232.6434\n",
      "Epoch 498/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -25564856.0074 - val_loss: -25404658.0000\n",
      "Epoch 499/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -25699108.0705 - val_loss: -25538470.8951\n",
      "Epoch 500/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -25834260.4032 - val_loss: -25671535.4126\n",
      "Epoch 501/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -25969529.8293 - val_loss: -25806645.1049\n",
      "Epoch 502/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -26105394.3970 - val_loss: -25941925.1189\n",
      "Epoch 503/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -26241906.2870 - val_loss: -26077173.7622\n",
      "Epoch 504/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -26378709.1429 - val_loss: -26212932.6993\n",
      "Epoch 505/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -26516070.8114 - val_loss: -26348602.0420\n",
      "Epoch 506/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -26653661.4113 - val_loss: -26485904.4755\n",
      "Epoch 507/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -26791867.9567 - val_loss: -26622538.6014\n",
      "Epoch 508/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -26930273.0748 - val_loss: -26761101.4965\n",
      "Epoch 509/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -27069583.8887 - val_loss: -26898143.9720\n",
      "Epoch 510/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -27208833.2851 - val_loss: -27036836.4336\n",
      "Epoch 511/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -27348861.3494 - val_loss: -27175985.9580\n",
      "Epoch 512/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -27489331.2072 - val_loss: -27315736.3077\n",
      "Epoch 513/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -27630439.6376 - val_loss: -27455136.1399\n",
      "Epoch 514/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -27771693.6994 - val_loss: -27595801.5245\n",
      "Epoch 515/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -27913781.5869 - val_loss: -27736914.1678\n",
      "Epoch 516/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -28056114.5850 - val_loss: -27878331.3846\n",
      "Epoch 517/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -28198844.3154 - val_loss: -28019920.2657\n",
      "Epoch 518/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -28342300.5108 - val_loss: -28161881.4266\n",
      "Epoch 519/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -28485965.9159 - val_loss: -28304969.1888\n",
      "Epoch 520/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -28630232.7087 - val_loss: -28447800.3776\n",
      "Epoch 521/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -28774979.1812 - val_loss: -28591656.5874\n",
      "Epoch 522/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -28920175.1701 - val_loss: -28736154.2238\n",
      "Epoch 523/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -29065991.0897 - val_loss: -28880222.6434\n",
      "Epoch 524/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -29212013.8961 - val_loss: -29026080.8531\n",
      "Epoch 525/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -29358691.2171 - val_loss: -29171489.8042\n",
      "Epoch 526/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -29505716.5566 - val_loss: -29317137.4266\n",
      "Epoch 527/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -29653155.1614 - val_loss: -29463479.4126\n",
      "Epoch 528/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -29801355.3494 - val_loss: -29610774.1259\n",
      "Epoch 529/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -29949851.0748 - val_loss: -29757738.7972\n",
      "Epoch 530/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -30098785.6722 - val_loss: -29906035.6503\n",
      "Epoch 531/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -30248546.1509 - val_loss: -30054294.2937\n",
      "Epoch 532/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -30398403.9975 - val_loss: -30203287.8881\n",
      "Epoch 533/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -30548864.3241 - val_loss: -30352729.0210\n",
      "Epoch 534/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -30699798.4712 - val_loss: -30502739.3007\n",
      "Epoch 535/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -30851149.2492 - val_loss: -30652391.8601\n",
      "Epoch 536/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -31003093.8986 - val_loss: -30803375.8042\n",
      "Epoch 537/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -31155477.0761 - val_loss: -30954609.0350\n",
      "Epoch 538/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -31308458.5566 - val_loss: -31106116.2797\n",
      "Epoch 539/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -31461722.2115 - val_loss: -31258629.0909\n",
      "Epoch 540/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -31615388.3426 - val_loss: -31411400.2657\n",
      "Epoch 541/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -31769722.4688 - val_loss: -31564511.7622\n",
      "Epoch 542/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -31924402.1027 - val_loss: -31717917.3706\n",
      "Epoch 543/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -32079716.8584 - val_loss: -31872573.6503\n",
      "Epoch 544/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -32235648.5071 - val_loss: -32026914.8951\n",
      "Epoch 545/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -32391922.1583 - val_loss: -32181834.7552\n",
      "Epoch 546/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -32548342.8324 - val_loss: -32337355.1329\n",
      "Epoch 547/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -32705513.7081 - val_loss: -32493680.0420\n",
      "Epoch 548/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -32863346.3203 - val_loss: -32649739.5105\n",
      "Epoch 549/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -33021312.5207 - val_loss: -32807379.5944\n",
      "Epoch 550/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -33180210.5071 - val_loss: -32964238.2937\n",
      "Epoch 551/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -33339165.7737 - val_loss: -33122252.9371\n",
      "Epoch 552/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -33498844.2968 - val_loss: -33281018.9930\n",
      "Epoch 553/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -33659156.1064 - val_loss: -33439832.5874\n",
      "Epoch 554/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -33819755.7328 - val_loss: -33599802.8531\n",
      "Epoch 555/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -33981151.5436 - val_loss: -33758698.2378\n",
      "Epoch 556/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -34142402.8806 - val_loss: -33919908.8392\n",
      "Epoch 557/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -34304782.6147 - val_loss: -34080033.4825\n",
      "Epoch 558/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -34467169.5993 - val_loss: -34242441.5385\n",
      "Epoch 559/600\n",
      "1617/1617 [==============================] - ETA: 0s - loss: -35054888.000 - 0s 35us/sample - loss: -34630415.1293 - val_loss: -34404229.8741\n",
      "Epoch 560/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -34793874.7805 - val_loss: -34566719.1888\n",
      "Epoch 561/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -34958327.1144 - val_loss: -34729198.2937\n",
      "Epoch 562/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -35123095.2999 - val_loss: -34892160.9510\n",
      "Epoch 563/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -35287951.8120 - val_loss: -35057200.5035\n",
      "Epoch 564/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -35453626.9635 - val_loss: -35221804.7552\n",
      "Epoch 565/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -35619833.7934 - val_loss: -35386109.6224\n",
      "Epoch 566/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -35786418.7483 - val_loss: -35551665.9860\n",
      "Epoch 567/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -35953604.3043 - val_loss: -35717310.0979\n",
      "Epoch 568/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -36121146.8250 - val_loss: -35883623.7203\n",
      "Epoch 569/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -36289102.4490 - val_loss: -36050948.7552\n",
      "Epoch 570/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -36457839.5993 - val_loss: -36218204.4196\n",
      "Epoch 571/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -36626785.3680 - val_loss: -36386186.0140\n",
      "Epoch 572/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -36796592.1509 - val_loss: -36553620.1399\n",
      "Epoch 573/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -36966581.5139 - val_loss: -36723000.2238\n",
      "Epoch 574/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -37137533.3531 - val_loss: -36891982.4615\n",
      "Epoch 575/600\n",
      "1617/1617 [==============================] - 0s 48us/sample - loss: -37308665.4793 - val_loss: -37062398.1259\n",
      "Epoch 576/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -37480365.3729 - val_loss: -37232860.1119\n",
      "Epoch 577/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -37652421.6401 - val_loss: -37403573.9580\n",
      "Epoch 578/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -37825093.7403 - val_loss: -37574491.1049\n",
      "Epoch 579/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -37998081.2294 - val_loss: -37746295.4965\n",
      "Epoch 580/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -38171595.9604 - val_loss: -37919138.3217\n",
      "Epoch 581/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -38346061.7563 - val_loss: -38092308.7273\n",
      "Epoch 582/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -38520847.3865 - val_loss: -38265678.8531\n",
      "Epoch 583/600\n",
      "1617/1617 [==============================] - 0s 53us/sample - loss: -38696208.3067 - val_loss: -38439507.4965\n",
      "Epoch 584/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -38871950.2560 - val_loss: -38614178.7133\n",
      "Epoch 585/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -39048250.3748 - val_loss: -38788943.6643\n",
      "Epoch 586/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -39224928.0470 - val_loss: -38964601.3986\n",
      "Epoch 587/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -39402477.5090 - val_loss: -39140777.5105\n",
      "Epoch 588/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -39580457.4917 - val_loss: -39317355.7203\n",
      "Epoch 589/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -39758744.7495 - val_loss: -39494189.2867\n",
      "Epoch 590/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -39937705.3333 - val_loss: -39671246.1818\n",
      "Epoch 591/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -40117089.9988 - val_loss: -39850153.9860\n",
      "Epoch 592/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -40297229.1305 - val_loss: -40028991.1049\n",
      "Epoch 593/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -40477562.1769 - val_loss: -40208601.3986\n",
      "Epoch 594/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -40658668.4626 - val_loss: -40387145.5944\n",
      "Epoch 595/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -40840012.1929 - val_loss: -40567701.5664\n",
      "Epoch 596/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -41022098.0087 - val_loss: -40748160.8392\n",
      "Epoch 597/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -41204631.8466 - val_loss: -40929302.9930\n",
      "Epoch 598/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -41387769.0291 - val_loss: -41110905.2867\n",
      "Epoch 599/600\n",
      "1617/1617 [==============================] - 0s 59us/sample - loss: -41571435.0229 - val_loss: -41292874.0420\n",
      "Epoch 600/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -41755225.9814 - val_loss: -41475777.5944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16bab811550>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=600,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16bba355f28>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8686176264167164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predictions=model.predict(X_test)\n",
    "print(mean_squared_error(y_test,predictions ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1617 samples, validate on 286 samples\n",
      "Epoch 1/600\n",
      "1617/1617 [==============================] - 0s 200us/sample - loss: 3.0049 - val_loss: 0.5894\n",
      "Epoch 2/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -3.6686 - val_loss: -7.3684\n",
      "Epoch 3/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -11.7975 - val_loss: -18.4185\n",
      "Epoch 4/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -25.8465 - val_loss: -32.6997\n",
      "Epoch 5/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -46.8162 - val_loss: -53.3330\n",
      "Epoch 6/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -75.6838 - val_loss: -87.5893\n",
      "Epoch 7/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -133.1253 - val_loss: -168.3209\n",
      "Epoch 8/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -233.2989 - val_loss: -286.9215\n",
      "Epoch 9/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -355.4213 - val_loss: -436.0425\n",
      "Epoch 10/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -524.6718 - val_loss: -625.0258\n",
      "Epoch 11/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -759.9330 - val_loss: -856.5011\n",
      "Epoch 12/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -933.8701 - val_loss: -1119.1874\n",
      "Epoch 13/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1347.0208 - val_loss: -1446.9576\n",
      "Epoch 14/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -1627.3607 - val_loss: -1810.4181\n",
      "Epoch 15/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -2035.1555 - val_loss: -2219.3687\n",
      "Epoch 16/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -2406.2465 - val_loss: -2676.9003\n",
      "Epoch 17/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2991.6157 - val_loss: -3190.1935\n",
      "Epoch 18/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -3428.3822 - val_loss: -3751.9666\n",
      "Epoch 19/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -4440.9146 - val_loss: -4416.4450\n",
      "Epoch 20/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -4885.5438 - val_loss: -5117.8094\n",
      "Epoch 21/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -5727.2735 - val_loss: -5871.1441\n",
      "Epoch 22/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -6345.5161 - val_loss: -6678.8654\n",
      "Epoch 23/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -7219.8215 - val_loss: -7546.2989\n",
      "Epoch 24/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: -7862.9661 - val_loss: -8432.5644\n",
      "Epoch 25/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -9106.6565 - val_loss: -9441.7532\n",
      "Epoch 26/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -10036.1069 - val_loss: -10474.5964\n",
      "Epoch 27/600\n",
      "1617/1617 [==============================] - 0s 60us/sample - loss: -11378.6668 - val_loss: -11634.1081\n",
      "Epoch 28/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -11767.8682 - val_loss: -12767.1209\n",
      "Epoch 29/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -14091.2735 - val_loss: -14045.2742\n",
      "Epoch 30/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -14820.8191 - val_loss: -15400.1292\n",
      "Epoch 31/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -16552.6652 - val_loss: -16806.0351\n",
      "Epoch 32/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -17125.6320 - val_loss: -18230.5260\n",
      "Epoch 33/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -19719.1123 - val_loss: -19787.2250\n",
      "Epoch 34/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -20299.3330 - val_loss: -21370.1432\n",
      "Epoch 35/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -22227.1508 - val_loss: -23040.8795\n",
      "Epoch 36/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: -24019.9548 - val_loss: -24757.1327\n",
      "Epoch 37/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -25430.7150 - val_loss: -26589.8069\n",
      "Epoch 38/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: -26907.2864 - val_loss: -28439.6377\n",
      "Epoch 39/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -29271.2205 - val_loss: -30384.0067\n",
      "Epoch 40/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -32629.0064 - val_loss: -32517.6580\n",
      "Epoch 41/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -33348.3147 - val_loss: -34665.2135\n",
      "Epoch 42/600\n",
      "1617/1617 [==============================] - 0s 62us/sample - loss: -36637.7544 - val_loss: -36884.1546\n",
      "Epoch 43/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -39661.8872 - val_loss: -39260.1245\n",
      "Epoch 44/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -40964.3166 - val_loss: -41667.7564\n",
      "Epoch 45/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -44121.6359 - val_loss: -44171.9875\n",
      "Epoch 46/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -44754.9887 - val_loss: -46668.6208\n",
      "Epoch 47/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -47815.0818 - val_loss: -49261.0332\n",
      "Epoch 48/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -50250.7164 - val_loss: -51927.0325\n",
      "Epoch 49/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -50505.2076 - val_loss: -54565.2567\n",
      "Epoch 50/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -57892.8357 - val_loss: -57487.0623\n",
      "Epoch 51/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -58976.8199 - val_loss: -60463.2112\n",
      "Epoch 52/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -63155.1805 - val_loss: -63546.3772\n",
      "Epoch 53/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -66551.7066 - val_loss: -66689.6306\n",
      "Epoch 54/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -69291.9362 - val_loss: -69962.1969\n",
      "Epoch 55/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -67327.6330 - val_loss: -73057.6741\n",
      "Epoch 56/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -75074.5466 - val_loss: -76427.0700\n",
      "Epoch 57/600\n",
      "1617/1617 [==============================] - 0s 54us/sample - loss: -77573.9530 - val_loss: -79854.0974\n",
      "Epoch 58/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -80657.4684 - val_loss: -83401.9397\n",
      "Epoch 59/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -85179.4868 - val_loss: -87059.3657\n",
      "Epoch 60/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -94845.1842 - val_loss: -90937.1634\n",
      "Epoch 61/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -96172.4786 - val_loss: -94877.4940\n",
      "Epoch 62/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -100461.9086 - val_loss: -98887.7206\n",
      "Epoch 63/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -99806.5285 - val_loss: -102843.3250\n",
      "Epoch 64/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -100037.4033 - val_loss: -106745.8830\n",
      "Epoch 65/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -109365.0650 - val_loss: -110905.7200\n",
      "Epoch 66/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -114036.0500 - val_loss: -115115.5376\n",
      "Epoch 67/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -117244.1863 - val_loss: -119507.0982\n",
      "Epoch 68/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -122627.7745 - val_loss: -123973.7691\n",
      "Epoch 69/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -130332.4376 - val_loss: -128612.7276\n",
      "Epoch 70/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -132643.5426 - val_loss: -133312.5127\n",
      "Epoch 71/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -146636.1636 - val_loss: -138277.7094\n",
      "Epoch 72/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -140808.4226 - val_loss: -143188.3346\n",
      "Epoch 73/600\n",
      "1617/1617 [==============================] - 0s 48us/sample - loss: -149615.2641 - val_loss: -148185.8951\n",
      "Epoch 74/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -147791.0187 - val_loss: -153109.4749\n",
      "Epoch 75/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -159308.4146 - val_loss: -158234.7670\n",
      "Epoch 76/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -166041.4942 - val_loss: -163524.1176\n",
      "Epoch 77/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -165735.4057 - val_loss: -168802.2811\n",
      "Epoch 78/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -172539.0464 - val_loss: -174152.5934\n",
      "Epoch 79/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -179967.5639 - val_loss: -179579.7179\n",
      "Epoch 80/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -178248.9808 - val_loss: -185124.8381\n",
      "Epoch 81/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -192641.0981 - val_loss: -190850.6430\n",
      "Epoch 82/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -198638.2845 - val_loss: -196690.3507\n",
      "Epoch 83/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -202704.4386 - val_loss: -202634.6346\n",
      "Epoch 84/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -211961.8026 - val_loss: -208781.3167\n",
      "Epoch 85/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -203758.6820 - val_loss: -214581.7198\n",
      "Epoch 86/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -230831.6729 - val_loss: -221053.6097\n",
      "Epoch 87/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -228259.7641 - val_loss: -227369.3385\n",
      "Epoch 88/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -230485.1125 - val_loss: -233751.9938\n",
      "Epoch 89/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -234649.0402 - val_loss: -240174.3089\n",
      "Epoch 90/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -243413.8033 - val_loss: -246685.0529\n",
      "Epoch 91/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -252528.7989 - val_loss: -253251.3061\n",
      "Epoch 92/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -256139.5015 - val_loss: -260106.7240\n",
      "Epoch 93/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -268868.4370 - val_loss: -267006.8816\n",
      "Epoch 94/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -271785.7547 - val_loss: -274099.8669\n",
      "Epoch 95/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -272030.2622 - val_loss: -280981.5780\n",
      "Epoch 96/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -298397.9668 - val_loss: -288440.9049\n",
      "Epoch 97/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -293247.0379 - val_loss: -295790.0140\n",
      "Epoch 98/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -298091.3941 - val_loss: -303128.3499\n",
      "Epoch 99/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -327591.7639 - val_loss: -310976.8669\n",
      "Epoch 100/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -314785.7739 - val_loss: -318638.9524\n",
      "Epoch 101/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -329983.6404 - val_loss: -326523.5566\n",
      "Epoch 102/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -351081.7672 - val_loss: -334793.9235\n",
      "Epoch 103/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -337906.3292 - val_loss: -342634.1080\n",
      "Epoch 104/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -358477.6235 - val_loss: -350857.9537\n",
      "Epoch 105/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -350928.7735 - val_loss: -358990.4226\n",
      "Epoch 106/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -361825.2775 - val_loss: -367182.2712\n",
      "Epoch 107/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -390055.3918 - val_loss: -375838.9602\n",
      "Epoch 108/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -388490.0184 - val_loss: -384416.6503\n",
      "Epoch 109/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -400351.4779 - val_loss: -393096.8365\n",
      "Epoch 110/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -401364.5061 - val_loss: -401756.5614\n",
      "Epoch 111/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -412087.2023 - val_loss: -410766.5151\n",
      "Epoch 112/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -405993.9113 - val_loss: -419301.5411\n",
      "Epoch 113/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -424040.4882 - val_loss: -428226.4351\n",
      "Epoch 114/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -425835.1392 - val_loss: -437218.6862\n",
      "Epoch 115/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -432079.9967 - val_loss: -446129.5310\n",
      "Epoch 116/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -451915.1292 - val_loss: -455456.3118\n",
      "Epoch 117/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -439698.0599 - val_loss: -464672.0656\n",
      "Epoch 118/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -485666.9761 - val_loss: -474370.1707\n",
      "Epoch 119/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -486011.2781 - val_loss: -484260.9392\n",
      "Epoch 120/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -492317.2206 - val_loss: -494050.7804\n",
      "Epoch 121/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -499729.3421 - val_loss: -503966.1104\n",
      "Epoch 122/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -511853.4739 - val_loss: -514053.3066\n",
      "Epoch 123/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -527845.2238 - val_loss: -524326.9218\n",
      "Epoch 124/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -531687.2293 - val_loss: -534743.3086\n",
      "Epoch 125/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -539190.7074 - val_loss: -545143.6302\n",
      "Epoch 126/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -567476.8617 - val_loss: -555763.0323\n",
      "Epoch 127/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: -550873.9697 - val_loss: -566434.3717\n",
      "Epoch 128/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -551284.0878 - val_loss: -576707.0660\n",
      "Epoch 129/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -577396.5745 - val_loss: -587565.9073\n",
      "Epoch 130/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -601557.9743 - val_loss: -598681.8365\n",
      "Epoch 131/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -611217.1268 - val_loss: -609949.4646\n",
      "Epoch 132/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -596251.6156 - val_loss: -620885.7421\n",
      "Epoch 133/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -626689.9986 - val_loss: -632364.1512\n",
      "Epoch 134/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -652406.0342 - val_loss: -643957.6892\n",
      "Epoch 135/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -684161.3893 - val_loss: -656043.6512\n",
      "Epoch 136/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -655645.5634 - val_loss: -667928.6591\n",
      "Epoch 137/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -681610.6294 - val_loss: -679803.4808\n",
      "Epoch 138/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -695273.5363 - val_loss: -691815.3055\n",
      "Epoch 139/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 32us/sample - loss: -710691.5581 - val_loss: -704209.2684\n",
      "Epoch 140/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -720838.2594 - val_loss: -716658.5516\n",
      "Epoch 141/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -711164.9905 - val_loss: -728842.4344\n",
      "Epoch 142/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -733215.9194 - val_loss: -741208.3562\n",
      "Epoch 143/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -716579.4289 - val_loss: -753419.9257\n",
      "Epoch 144/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -772361.1502 - val_loss: -766301.8182\n",
      "Epoch 145/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -775640.5117 - val_loss: -779048.7024\n",
      "Epoch 146/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -794442.8445 - val_loss: -792255.4362\n",
      "Epoch 147/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -765725.1080 - val_loss: -804960.4572\n",
      "Epoch 148/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -811845.5057 - val_loss: -818271.8134\n",
      "Epoch 149/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -832621.0985 - val_loss: -831798.3571\n",
      "Epoch 150/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -821074.9253 - val_loss: -845231.2487\n",
      "Epoch 151/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -888350.4550 - val_loss: -859357.4747\n",
      "Epoch 152/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -913106.8725 - val_loss: -873935.7990\n",
      "Epoch 153/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -890406.0720 - val_loss: -888041.8462\n",
      "Epoch 154/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -850808.2585 - val_loss: -901619.0415\n",
      "Epoch 155/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -969917.4184 - val_loss: -916446.0219\n",
      "Epoch 156/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -925033.1933 - val_loss: -930869.3177\n",
      "Epoch 157/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -924345.6451 - val_loss: -945291.1534\n",
      "Epoch 158/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -982679.6316 - val_loss: -960189.1744\n",
      "Epoch 159/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1014660.4290 - val_loss: -975494.3466\n",
      "Epoch 160/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -974076.1451 - val_loss: -990349.9253\n",
      "Epoch 161/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1009626.4170 - val_loss: -1005464.1368\n",
      "Epoch 162/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1021991.3085 - val_loss: -1020827.8942\n",
      "Epoch 163/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1041716.6504 - val_loss: -1036190.3348\n",
      "Epoch 164/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -1038599.4815 - val_loss: -1051511.0612\n",
      "Epoch 165/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1076535.4719 - val_loss: -1067051.4515\n",
      "Epoch 166/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1088497.0218 - val_loss: -1082807.6809\n",
      "Epoch 167/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1111843.0034 - val_loss: -1099107.5979\n",
      "Epoch 168/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1044669.8227 - val_loss: -1114015.7177\n",
      "Epoch 169/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1127094.1771 - val_loss: -1130177.4677\n",
      "Epoch 170/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1129668.9647 - val_loss: -1146153.9904\n",
      "Epoch 171/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -1090834.4592 - val_loss: -1161944.4196\n",
      "Epoch 172/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1183868.9139 - val_loss: -1178388.2762\n",
      "Epoch 173/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1163999.8710 - val_loss: -1194964.8514\n",
      "Epoch 174/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1199792.7706 - val_loss: -1211311.3960\n",
      "Epoch 175/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1219497.0901 - val_loss: -1228573.4283\n",
      "Epoch 176/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1288637.0732 - val_loss: -1246572.5542\n",
      "Epoch 177/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1252909.3703 - val_loss: -1263778.1635\n",
      "Epoch 178/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1273283.7488 - val_loss: -1281163.0358\n",
      "Epoch 179/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1291913.4762 - val_loss: -1298511.1163\n",
      "Epoch 180/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1351171.0407 - val_loss: -1316855.0035\n",
      "Epoch 181/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1371520.8353 - val_loss: -1335230.5332\n",
      "Epoch 182/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1365941.1827 - val_loss: -1353590.1198\n",
      "Epoch 183/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1357917.5094 - val_loss: -1371463.6364\n",
      "Epoch 184/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1432583.3794 - val_loss: -1390487.7430\n",
      "Epoch 185/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1376246.1311 - val_loss: -1408589.3156\n",
      "Epoch 186/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1445244.9661 - val_loss: -1427416.4108\n",
      "Epoch 187/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1399149.3511 - val_loss: -1446018.8890\n",
      "Epoch 188/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1480209.3803 - val_loss: -1465117.2334\n",
      "Epoch 189/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1494248.0921 - val_loss: -1484169.0385\n",
      "Epoch 190/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1489633.2948 - val_loss: -1503292.8724\n",
      "Epoch 191/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -1530935.0935 - val_loss: -1522974.7247\n",
      "Epoch 192/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -1564225.5100 - val_loss: -1542922.0726\n",
      "Epoch 193/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1650293.2831 - val_loss: -1563332.7955\n",
      "Epoch 194/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1661797.1187 - val_loss: -1584215.6565\n",
      "Epoch 195/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1591526.6550 - val_loss: -1604065.3881\n",
      "Epoch 196/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1592621.8836 - val_loss: -1624005.8907\n",
      "Epoch 197/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1679544.3458 - val_loss: -1644461.3234\n",
      "Epoch 198/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1562628.0090 - val_loss: -1663521.3191\n",
      "Epoch 199/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -1694165.4266 - val_loss: -1683975.0892\n",
      "Epoch 200/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1645510.1549 - val_loss: -1704614.9624\n",
      "Epoch 201/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1794959.5215 - val_loss: -1726028.1390\n",
      "Epoch 202/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1804330.1181 - val_loss: -1747649.7544\n",
      "Epoch 203/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1729988.9652 - val_loss: -1768578.2937\n",
      "Epoch 204/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1820788.9901 - val_loss: -1790386.8698\n",
      "Epoch 205/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1836209.6771 - val_loss: -1812221.8453\n",
      "Epoch 206/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1810754.7249 - val_loss: -1833760.2622\n",
      "Epoch 207/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -1881857.7965 - val_loss: -1855821.7509\n",
      "Epoch 208/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -1870042.1775 - val_loss: -1877820.4135\n",
      "Epoch 209/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1972449.4491 - val_loss: -1900776.2850\n",
      "Epoch 210/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -1970313.6538 - val_loss: -1923715.7509\n",
      "Epoch 211/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -1946044.7202 - val_loss: -1946342.1075\n",
      "Epoch 212/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -1946384.1867 - val_loss: -1968398.2509\n",
      "Epoch 213/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2038535.1865 - val_loss: -1991750.1949\n",
      "Epoch 214/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2130536.4957 - val_loss: -2015843.3278\n",
      "Epoch 215/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2023889.4552 - val_loss: -2039036.3173\n",
      "Epoch 216/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2015692.2758 - val_loss: -2061809.8287\n",
      "Epoch 217/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2161005.4890 - val_loss: -2085650.3077\n",
      "Epoch 218/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2100259.9641 - val_loss: -2109330.0603\n",
      "Epoch 219/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -2119814.7219 - val_loss: -2133175.7797\n",
      "Epoch 220/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2100216.1582 - val_loss: -2156483.8715\n",
      "Epoch 221/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2098482.6844 - val_loss: -2179871.7360\n",
      "Epoch 222/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -2167226.4552 - val_loss: -2203577.9755\n",
      "Epoch 223/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2273185.1948 - val_loss: -2228638.5752\n",
      "Epoch 224/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2232404.4954 - val_loss: -2252931.4808\n",
      "Epoch 225/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2304818.5405 - val_loss: -2278357.8864\n",
      "Epoch 226/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2325334.4358 - val_loss: -2303793.6871\n",
      "Epoch 227/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2376962.2279 - val_loss: -2329004.2885\n",
      "Epoch 228/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -2370418.2921 - val_loss: -2354805.2098\n",
      "Epoch 229/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2385141.7916 - val_loss: -2380537.7500\n",
      "Epoch 230/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2469844.5533 - val_loss: -2406602.2220\n",
      "Epoch 231/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2344321.5322 - val_loss: -2432061.7500\n",
      "Epoch 232/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -2408991.3671 - val_loss: -2457540.7483\n",
      "Epoch 233/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2466501.1112 - val_loss: -2483314.2115\n",
      "Epoch 234/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2598025.9176 - val_loss: -2510706.1888\n",
      "Epoch 235/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2526129.5202 - val_loss: -2537267.9685\n",
      "Epoch 236/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2587643.1708 - val_loss: -2564265.6766\n",
      "Epoch 237/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -2607394.4168 - val_loss: -2591391.3304\n",
      "Epoch 238/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2675973.9087 - val_loss: -2619010.1538\n",
      "Epoch 239/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2770260.5254 - val_loss: -2647202.1818\n",
      "Epoch 240/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2643513.8437 - val_loss: -2674434.1434\n",
      "Epoch 241/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2745284.4787 - val_loss: -2702286.0140\n",
      "Epoch 242/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2718306.1861 - val_loss: -2730083.8094\n",
      "Epoch 243/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2710851.4357 - val_loss: -2757477.3059\n",
      "Epoch 244/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2771515.6170 - val_loss: -2786060.0035\n",
      "Epoch 245/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2717136.2730 - val_loss: -2812989.3042\n",
      "Epoch 246/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -2902188.8231 - val_loss: -2842250.5559\n",
      "Epoch 247/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -2848480.6107 - val_loss: -2871176.3811\n",
      "Epoch 248/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -2999086.9366 - val_loss: -2900669.1364\n",
      "Epoch 249/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -2879612.6875 - val_loss: -2929811.5524\n",
      "Epoch 250/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -3046124.0686 - val_loss: -2959232.2902\n",
      "Epoch 251/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -2965541.7225 - val_loss: -2988680.2902\n",
      "Epoch 252/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -2994988.9200 - val_loss: -3018245.9825\n",
      "Epoch 253/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -3049350.9250 - val_loss: -3047798.4161\n",
      "Epoch 254/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -3094179.2438 - val_loss: -3077963.7430\n",
      "Epoch 255/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3142833.5921 - val_loss: -3108444.0315\n",
      "Epoch 256/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -3130036.2819 - val_loss: -3138963.1836\n",
      "Epoch 257/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -3269476.0422 - val_loss: -3170082.6958\n",
      "Epoch 258/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -3093360.3789 - val_loss: -3199821.0664\n",
      "Epoch 259/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -3158511.6574 - val_loss: -3230282.0035\n",
      "Epoch 260/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -3298471.2486 - val_loss: -3261284.1399\n",
      "Epoch 261/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -3359011.2925 - val_loss: -3293347.2517\n",
      "Epoch 262/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -3494219.2375 - val_loss: -3326143.6241\n",
      "Epoch 263/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -3504593.6846 - val_loss: -3359035.2115\n",
      "Epoch 264/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -3305964.4858 - val_loss: -3390509.2762\n",
      "Epoch 265/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -3402769.9140 - val_loss: -3421956.1626\n",
      "Epoch 266/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -3453969.5475 - val_loss: -3454169.0874\n",
      "Epoch 267/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -3558281.9239 - val_loss: -3486783.3287\n",
      "Epoch 268/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -3547933.3633 - val_loss: -3520090.4738\n",
      "Epoch 269/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -3594927.5625 - val_loss: -3553270.5227\n",
      "Epoch 270/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -3790751.2285 - val_loss: -3587111.7325\n",
      "Epoch 271/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -3488554.9966 - val_loss: -3619866.4633\n",
      "Epoch 272/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -3667717.5158 - val_loss: -3652706.7395\n",
      "Epoch 273/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 43us/sample - loss: -3834895.0478 - val_loss: -3687100.3899\n",
      "Epoch 274/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -3750992.2208 - val_loss: -3720916.6678\n",
      "Epoch 275/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -3788337.0207 - val_loss: -3754923.0787\n",
      "Epoch 276/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -3920414.4273 - val_loss: -3789940.7657\n",
      "Epoch 277/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -3752556.6551 - val_loss: -3823796.8199\n",
      "Epoch 278/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -3744094.3596 - val_loss: -3857263.3846\n",
      "Epoch 279/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -3698531.0317 - val_loss: -3890312.4423\n",
      "Epoch 280/600\n",
      "1617/1617 [==============================] - 0s 57us/sample - loss: -3950015.4481 - val_loss: -3924754.9143\n",
      "Epoch 281/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -4016556.8024 - val_loss: -3960240.3287\n",
      "Epoch 282/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -4103402.3046 - val_loss: -3996368.7780\n",
      "Epoch 283/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -3984393.3012 - val_loss: -4031706.5280\n",
      "Epoch 284/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -4217816.0309 - val_loss: -4068273.7063\n",
      "Epoch 285/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -3978394.2713 - val_loss: -4103280.7622\n",
      "Epoch 286/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -4060886.3196 - val_loss: -4138219.3322\n",
      "Epoch 287/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -4294352.4824 - val_loss: -4175342.3899\n",
      "Epoch 288/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -4078199.8312 - val_loss: -4210909.8899\n",
      "Epoch 289/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -4283468.4007 - val_loss: -4247325.4213\n",
      "Epoch 290/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -4423664.1797 - val_loss: -4285277.0420\n",
      "Epoch 291/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -4373460.5813 - val_loss: -4322219.5559\n",
      "Epoch 292/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4498709.2055 - val_loss: -4361180.1259\n",
      "Epoch 293/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4334697.2276 - val_loss: -4398338.8147\n",
      "Epoch 294/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4377886.0059 - val_loss: -4435093.9860\n",
      "Epoch 295/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4352114.6418 - val_loss: -4471968.9126\n",
      "Epoch 296/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -4458348.2665 - val_loss: -4509329.2867\n",
      "Epoch 297/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4624552.8635 - val_loss: -4548161.6748\n",
      "Epoch 298/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4629193.2981 - val_loss: -4586886.8217\n",
      "Epoch 299/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4602715.2801 - val_loss: -4625804.7238\n",
      "Epoch 300/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -4721333.5340 - val_loss: -4664928.0874\n",
      "Epoch 301/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4672177.1274 - val_loss: -4704044.7517\n",
      "Epoch 302/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -5102299.7248 - val_loss: -4745611.0350\n",
      "Epoch 303/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -5002690.9627 - val_loss: -4786757.6538\n",
      "Epoch 304/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -4746566.8285 - val_loss: -4826427.8846\n",
      "Epoch 305/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -4960596.3578 - val_loss: -4866649.7692\n",
      "Epoch 306/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -5073927.0170 - val_loss: -4907168.5909\n",
      "Epoch 307/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -5029082.5649 - val_loss: -4948674.5559\n",
      "Epoch 308/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5002410.7083 - val_loss: -4988804.8566\n",
      "Epoch 309/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -4898296.7515 - val_loss: -5028588.1748\n",
      "Epoch 310/600\n",
      "1617/1617 [==============================] - 0s 54us/sample - loss: -4992180.5553 - val_loss: -5068710.7552\n",
      "Epoch 311/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -5174112.0346 - val_loss: -5109778.2902\n",
      "Epoch 312/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5258222.4405 - val_loss: -5152049.8112\n",
      "Epoch 313/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5276820.4997 - val_loss: -5194156.6958\n",
      "Epoch 314/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5209888.2684 - val_loss: -5235729.6049\n",
      "Epoch 315/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -5334928.7495 - val_loss: -5277803.7273\n",
      "Epoch 316/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5337967.7171 - val_loss: -5320105.5140\n",
      "Epoch 317/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5297866.8126 - val_loss: -5361909.6853\n",
      "Epoch 318/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5281314.1224 - val_loss: -5403331.7657\n",
      "Epoch 319/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5492904.9867 - val_loss: -5446467.0944\n",
      "Epoch 320/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5635023.2053 - val_loss: -5490480.1573\n",
      "Epoch 321/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -5972214.5541 - val_loss: -5536801.8811\n",
      "Epoch 322/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -5640040.6528 - val_loss: -5580993.0175\n",
      "Epoch 323/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -5735467.0263 - val_loss: -5625372.1399\n",
      "Epoch 324/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -5642211.3216 - val_loss: -5668867.3112\n",
      "Epoch 325/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -5879256.9023 - val_loss: -5714306.4825\n",
      "Epoch 326/600\n",
      "1617/1617 [==============================] - 0s 51us/sample - loss: -5779937.6113 - val_loss: -5758390.9895\n",
      "Epoch 327/600\n",
      "1617/1617 [==============================] - 0s 46us/sample - loss: -5834647.4873 - val_loss: -5803297.7972\n",
      "Epoch 328/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -5778792.0567 - val_loss: -5847712.2063\n",
      "Epoch 329/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -5769781.0210 - val_loss: -5890994.1399\n",
      "Epoch 330/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -6100313.5164 - val_loss: -5936604.1643\n",
      "Epoch 331/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -5970261.9041 - val_loss: -5982271.7762\n",
      "Epoch 332/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -6097401.5501 - val_loss: -6027683.6818\n",
      "Epoch 333/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -6281818.4847 - val_loss: -6075393.8601\n",
      "Epoch 334/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6307414.0674 - val_loss: -6121675.0210\n",
      "Epoch 335/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -5945984.8083 - val_loss: -6167194.2238\n",
      "Epoch 336/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6445302.4511 - val_loss: -6215484.9476\n",
      "Epoch 337/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6329721.5875 - val_loss: -6262765.1329\n",
      "Epoch 338/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -6056634.2208 - val_loss: -6308166.5664\n",
      "Epoch 339/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -6383762.5903 - val_loss: -6354759.3497\n",
      "Epoch 340/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -6553440.2291 - val_loss: -6402939.0909\n",
      "Epoch 341/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6870249.5284 - val_loss: -6453182.1678\n",
      "Epoch 342/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6473124.2882 - val_loss: -6501115.7168\n",
      "Epoch 343/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -6658856.3670 - val_loss: -6550076.9476\n",
      "Epoch 344/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6487900.8432 - val_loss: -6597221.3566\n",
      "Epoch 345/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6380423.6797 - val_loss: -6643839.8497\n",
      "Epoch 346/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -6791655.3757 - val_loss: -6693092.7448\n",
      "Epoch 347/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -6808840.2628 - val_loss: -6742588.0979\n",
      "Epoch 348/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -7004622.9610 - val_loss: -6793050.9615\n",
      "Epoch 349/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6792462.8466 - val_loss: -6842561.0804\n",
      "Epoch 350/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -7128737.6252 - val_loss: -6893102.0175\n",
      "Epoch 351/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -6944834.7520 - val_loss: -6943445.4615\n",
      "Epoch 352/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6831153.4354 - val_loss: -6992275.5769\n",
      "Epoch 353/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -7010457.6153 - val_loss: -7041963.9266\n",
      "Epoch 354/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -6929398.7505 - val_loss: -7091664.6573\n",
      "Epoch 355/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -7222884.4332 - val_loss: -7142726.1748\n",
      "Epoch 356/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -7007910.1197 - val_loss: -7192290.9545\n",
      "Epoch 357/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -7098689.2437 - val_loss: -7242933.5594\n",
      "Epoch 358/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -7287927.3525 - val_loss: -7294114.9615\n",
      "Epoch 359/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -7763156.0928 - val_loss: -7348852.5769\n",
      "Epoch 360/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -7193812.8185 - val_loss: -7399765.1923\n",
      "Epoch 361/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -7458154.4765 - val_loss: -7451905.7238\n",
      "Epoch 362/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -7471681.3281 - val_loss: -7504537.3986\n",
      "Epoch 363/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -7630061.5943 - val_loss: -7557862.3706\n",
      "Epoch 364/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -7338992.2975 - val_loss: -7609418.0839\n",
      "Epoch 365/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -7859900.4004 - val_loss: -7663446.4685\n",
      "Epoch 366/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -7399260.0943 - val_loss: -7714793.5035\n",
      "Epoch 367/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -7328913.2130 - val_loss: -7766242.7937\n",
      "Epoch 368/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -7989777.1994 - val_loss: -7820940.4091\n",
      "Epoch 369/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -7826298.4613 - val_loss: -7874317.5594\n",
      "Epoch 370/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -8166525.9239 - val_loss: -7930151.7692\n",
      "Epoch 371/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -8017034.2709 - val_loss: -7986966.1364\n",
      "Epoch 372/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -8139677.1153 - val_loss: -8042135.0769\n",
      "Epoch 373/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -7710814.7443 - val_loss: -8095328.4336\n",
      "Epoch 374/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -8086619.8411 - val_loss: -8150146.3112\n",
      "Epoch 375/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -8469100.7130 - val_loss: -8207004.8357\n",
      "Epoch 376/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -8558303.4508 - val_loss: -8264761.4580\n",
      "Epoch 377/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -8446232.0377 - val_loss: -8322386.6993\n",
      "Epoch 378/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -8537763.5269 - val_loss: -8380166.2133\n",
      "Epoch 379/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -8036061.1391 - val_loss: -8434406.1923\n",
      "Epoch 380/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -8587887.8145 - val_loss: -8491326.6783\n",
      "Epoch 381/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -8206662.5059 - val_loss: -8547516.6783\n",
      "Epoch 382/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -8562380.4898 - val_loss: -8605103.8497\n",
      "Epoch 383/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -8652083.1237 - val_loss: -8662438.5385\n",
      "Epoch 384/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -8640162.9666 - val_loss: -8720150.8776\n",
      "Epoch 385/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -8843292.7532 - val_loss: -8778857.2168\n",
      "Epoch 386/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -8469659.3531 - val_loss: -8835739.0280\n",
      "Epoch 387/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -9250608.5318 - val_loss: -8896308.9580\n",
      "Epoch 388/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -9120023.8423 - val_loss: -8955994.9371\n",
      "Epoch 389/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -9248384.5212 - val_loss: -9016655.1538\n",
      "Epoch 390/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -9550652.3915 - val_loss: -9078580.6783\n",
      "Epoch 391/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -9243321.3312 - val_loss: -9138908.6573\n",
      "Epoch 392/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -9690793.3556 - val_loss: -9201864.1538\n",
      "Epoch 393/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -9900385.4304 - val_loss: -9265678.2517\n",
      "Epoch 394/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -9443591.7458 - val_loss: -9326252.4126\n",
      "Epoch 395/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -9646780.8324 - val_loss: -9387329.2308\n",
      "Epoch 396/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -9534145.5170 - val_loss: -9449325.5455\n",
      "Epoch 397/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -9591819.6531 - val_loss: -9510432.9441\n",
      "Epoch 398/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -9670817.6224 - val_loss: -9570667.7692\n",
      "Epoch 399/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -9921515.7959 - val_loss: -9634006.6364\n",
      "Epoch 400/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -9862555.0983 - val_loss: -9696632.9510\n",
      "Epoch 401/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -9508335.8868 - val_loss: -9757540.0140\n",
      "Epoch 402/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -9721433.5411 - val_loss: -9818149.6783\n",
      "Epoch 403/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -9732666.0257 - val_loss: -9880025.5524\n",
      "Epoch 404/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -9748073.4527 - val_loss: -9940443.9371\n",
      "Epoch 405/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10068826.8472 - val_loss: -10003712.8112\n",
      "Epoch 406/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -9526393.8231 - val_loss: -10062794.3566\n",
      "Epoch 407/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 28us/sample - loss: -10220405.2795 - val_loss: -10127162.6573\n",
      "Epoch 408/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10246635.5714 - val_loss: -10191359.8462\n",
      "Epoch 409/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10486671.2653 - val_loss: -10257097.6853\n",
      "Epoch 410/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -10403926.2022 - val_loss: -10321428.7273\n",
      "Epoch 411/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -10141226.3482 - val_loss: -10385257.5175\n",
      "Epoch 412/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -10318379.5238 - val_loss: -10449463.8531\n",
      "Epoch 413/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10592191.3284 - val_loss: -10513966.8182\n",
      "Epoch 414/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10730030.7904 - val_loss: -10580640.4266\n",
      "Epoch 415/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10586706.5677 - val_loss: -10645697.7972\n",
      "Epoch 416/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10778405.9066 - val_loss: -10712169.9790\n",
      "Epoch 417/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -11020667.4657 - val_loss: -10779694.2238\n",
      "Epoch 418/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11409458.9592 - val_loss: -10849361.5524\n",
      "Epoch 419/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11086222.4787 - val_loss: -10916981.9161\n",
      "Epoch 420/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -10808753.0724 - val_loss: -10982532.4825\n",
      "Epoch 421/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11356659.0829 - val_loss: -11051507.4056\n",
      "Epoch 422/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -10561380.0742 - val_loss: -11116363.2308\n",
      "Epoch 423/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -11752725.8714 - val_loss: -11186637.6573\n",
      "Epoch 424/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10961486.1843 - val_loss: -11252511.2378\n",
      "Epoch 425/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -10989957.6327 - val_loss: -11318884.2028\n",
      "Epoch 426/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11115104.1772 - val_loss: -11386234.8601\n",
      "Epoch 427/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -11534156.9610 - val_loss: -11454484.5804\n",
      "Epoch 428/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11531272.2706 - val_loss: -11524245.0839\n",
      "Epoch 429/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11525175.5368 - val_loss: -11592869.8531\n",
      "Epoch 430/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -12179834.1763 - val_loss: -11664762.6014\n",
      "Epoch 431/600\n",
      "1617/1617 [==============================] - 0s 36us/sample - loss: -11749685.7341 - val_loss: -11735481.4965\n",
      "Epoch 432/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -11672617.8893 - val_loss: -11804558.6643\n",
      "Epoch 433/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -12354164.1153 - val_loss: -11877970.3147\n",
      "Epoch 434/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11856034.4116 - val_loss: -11948698.7063\n",
      "Epoch 435/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11716516.3652 - val_loss: -12017571.6014\n",
      "Epoch 436/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -12133295.3469 - val_loss: -12088729.7972\n",
      "Epoch 437/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -12041841.5683 - val_loss: -12159636.3916\n",
      "Epoch 438/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -12539366.4428 - val_loss: -12232022.0909\n",
      "Epoch 439/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11949697.3194 - val_loss: -12303119.8671\n",
      "Epoch 440/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -11707588.6642 - val_loss: -12372072.3986\n",
      "Epoch 441/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -12490172.5121 - val_loss: -12443556.6503\n",
      "Epoch 442/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -12847922.8423 - val_loss: -12519153.5315\n",
      "Epoch 443/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -12833777.6036 - val_loss: -12593191.8601\n",
      "Epoch 444/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -12425897.6846 - val_loss: -12665997.9720\n",
      "Epoch 445/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -12738640.7631 - val_loss: -12740728.3636\n",
      "Epoch 446/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -12926202.3661 - val_loss: -12814809.2657\n",
      "Epoch 447/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -12623095.0563 - val_loss: -12888092.7972\n",
      "Epoch 448/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -13363449.9499 - val_loss: -12965781.2238\n",
      "Epoch 449/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -13385085.0204 - val_loss: -13042441.2937\n",
      "Epoch 450/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -13120529.6834 - val_loss: -13117455.2378\n",
      "Epoch 451/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -12837000.4886 - val_loss: -13192107.9301\n",
      "Epoch 452/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -13262092.5912 - val_loss: -13267545.1608\n",
      "Epoch 453/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -13491193.8306 - val_loss: -13343825.4476\n",
      "Epoch 454/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -13915928.0532 - val_loss: -13422885.4755\n",
      "Epoch 455/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -13354579.6821 - val_loss: -13499261.4336\n",
      "Epoch 456/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -13552987.0340 - val_loss: -13575809.3636\n",
      "Epoch 457/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -13354664.1323 - val_loss: -13650628.5175\n",
      "Epoch 458/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -13325385.0550 - val_loss: -13726356.8252\n",
      "Epoch 459/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -13730147.5832 - val_loss: -13803315.1538\n",
      "Epoch 460/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -14132819.9252 - val_loss: -13882874.8322\n",
      "Epoch 461/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -13465984.6803 - val_loss: -13958318.9720\n",
      "Epoch 462/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14470690.3537 - val_loss: -14038287.9930\n",
      "Epoch 463/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -14193801.7341 - val_loss: -14119111.5804\n",
      "Epoch 464/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -14528228.6945 - val_loss: -14199817.3566\n",
      "Epoch 465/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14262421.5387 - val_loss: -14279209.3846\n",
      "Epoch 466/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14348334.4329 - val_loss: -14358404.2028\n",
      "Epoch 467/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14309436.0408 - val_loss: -14438053.9231\n",
      "Epoch 468/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -14955001.6178 - val_loss: -14519774.9650\n",
      "Epoch 469/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14729705.4731 - val_loss: -14601441.0000\n",
      "Epoch 470/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14439434.2968 - val_loss: -14682905.8741\n",
      "Epoch 471/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15944316.3377 - val_loss: -14767173.4895\n",
      "Epoch 472/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15264368.8040 - val_loss: -14852653.1678\n",
      "Epoch 473/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -15668551.5980 - val_loss: -14938319.0350\n",
      "Epoch 474/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14676707.9041 - val_loss: -15017510.8951\n",
      "Epoch 475/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -15461434.8015 - val_loss: -15101378.5524\n",
      "Epoch 476/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14853142.8064 - val_loss: -15182150.9231\n",
      "Epoch 477/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15079273.1435 - val_loss: -15263706.4056\n",
      "Epoch 478/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15779498.2975 - val_loss: -15349026.7902\n",
      "Epoch 479/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -15598588.0544 - val_loss: -15432367.1329\n",
      "Epoch 480/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -15606722.6506 - val_loss: -15515886.9441\n",
      "Epoch 481/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15114280.3964 - val_loss: -15597187.6224\n",
      "Epoch 482/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15247615.8924 - val_loss: -15678889.5105\n",
      "Epoch 483/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15751260.6685 - val_loss: -15762967.7133\n",
      "Epoch 484/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -14948102.3401 - val_loss: -15843913.1678\n",
      "Epoch 485/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -16694295.8602 - val_loss: -15929697.7063\n",
      "Epoch 486/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -16198087.6061 - val_loss: -16017747.9021\n",
      "Epoch 487/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -16092874.0383 - val_loss: -16103657.4825\n",
      "Epoch 488/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15671367.6002 - val_loss: -16187863.7622\n",
      "Epoch 489/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -15874475.8516 - val_loss: -16271248.9021\n",
      "Epoch 490/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -16414413.9023 - val_loss: -16358588.3357\n",
      "Epoch 491/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -15940960.2907 - val_loss: -16443360.0769\n",
      "Epoch 492/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -16058515.6994 - val_loss: -16527716.9231\n",
      "Epoch 493/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -16409764.4663 - val_loss: -16614548.0000\n",
      "Epoch 494/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -16589984.3018 - val_loss: -16702075.3776\n",
      "Epoch 495/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -16288522.3741 - val_loss: -16788248.7413\n",
      "Epoch 496/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -16085748.3612 - val_loss: -16874094.6294\n",
      "Epoch 497/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -17145471.7223 - val_loss: -16963315.0490\n",
      "Epoch 498/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -18139212.4131 - val_loss: -17057676.7762\n",
      "Epoch 499/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -17929995.4595 - val_loss: -17151774.0140\n",
      "Epoch 500/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -17029527.8281 - val_loss: -17241399.9860\n",
      "Epoch 501/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -16786281.8002 - val_loss: -17330270.5455\n",
      "Epoch 502/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -17879443.6586 - val_loss: -17422450.6503\n",
      "Epoch 503/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -17712895.3197 - val_loss: -17513542.4476\n",
      "Epoch 504/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -17194456.7013 - val_loss: -17603419.6503\n",
      "Epoch 505/600\n",
      "1617/1617 [==============================] - 0s 54us/sample - loss: -17710415.7038 - val_loss: -17693874.6014\n",
      "Epoch 506/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -18242750.8460 - val_loss: -17788941.8182\n",
      "Epoch 507/600\n",
      "1617/1617 [==============================] - 0s 58us/sample - loss: -17662942.0445 - val_loss: -17879779.7762\n",
      "Epoch 508/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -17503863.6376 - val_loss: -17968868.2378\n",
      "Epoch 509/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -18394624.9672 - val_loss: -18063779.3287\n",
      "Epoch 510/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -18694346.1608 - val_loss: -18158875.1888\n",
      "Epoch 511/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -18377478.3550 - val_loss: -18252995.2727\n",
      "Epoch 512/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -18137041.1775 - val_loss: -18346393.2028\n",
      "Epoch 513/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -18854706.4032 - val_loss: -18440929.0210\n",
      "Epoch 514/600\n",
      "1617/1617 [==============================] - 0s 34us/sample - loss: -17701113.4564 - val_loss: -18531997.1748\n",
      "Epoch 515/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -18685700.1583 - val_loss: -18626429.3007\n",
      "Epoch 516/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -19221822.0952 - val_loss: -18723275.5524\n",
      "Epoch 517/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -20498423.3135 - val_loss: -18826061.5245\n",
      "Epoch 518/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -19786787.6797 - val_loss: -18924603.2308\n",
      "Epoch 519/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -19632514.6024 - val_loss: -19022416.7692\n",
      "Epoch 520/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -19221287.8330 - val_loss: -19118807.0490\n",
      "Epoch 521/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -18934883.6630 - val_loss: -19213938.3497\n",
      "Epoch 522/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -19680838.8139 - val_loss: -19310039.8881\n",
      "Epoch 523/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -20648345.3976 - val_loss: -19411315.3427\n",
      "Epoch 524/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -19573390.1323 - val_loss: -19509943.5944\n",
      "Epoch 525/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -19311899.4855 - val_loss: -19604570.7133\n",
      "Epoch 526/600\n",
      "1617/1617 [==============================] - 0s 32us/sample - loss: -19836816.7322 - val_loss: -19702776.5734\n",
      "Epoch 527/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -19472043.3098 - val_loss: -19798907.1748\n",
      "Epoch 528/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -20442278.5838 - val_loss: -19898587.5944\n",
      "Epoch 529/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -20378311.6425 - val_loss: -19998698.3357\n",
      "Epoch 530/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -19116821.7477 - val_loss: -20092725.7902\n",
      "Epoch 531/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -20423902.1596 - val_loss: -20191418.5734\n",
      "Epoch 532/600\n",
      "1617/1617 [==============================] - 0s 37us/sample - loss: -20153606.5535 - val_loss: -20290495.1189\n",
      "Epoch 533/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -19428615.5164 - val_loss: -20385606.6294\n",
      "Epoch 534/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -21756084.6951 - val_loss: -20491035.5804\n",
      "Epoch 535/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -20625924.4230 - val_loss: -20591903.1608\n",
      "Epoch 536/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -21027798.9957 - val_loss: -20693839.5105\n",
      "Epoch 537/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -20989411.6054 - val_loss: -20796214.7832\n",
      "Epoch 538/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -20799920.8819 - val_loss: -20896353.9860\n",
      "Epoch 539/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 28us/sample - loss: -21446338.3278 - val_loss: -20999814.5315\n",
      "Epoch 540/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -21082835.5424 - val_loss: -21102630.3916\n",
      "Epoch 541/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -20648365.6747 - val_loss: -21201908.4056\n",
      "Epoch 542/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -20921267.9344 - val_loss: -21303408.1119\n",
      "Epoch 543/600\n",
      "1617/1617 [==============================] - 0s 38us/sample - loss: -21896759.2529 - val_loss: -21406701.1329\n",
      "Epoch 544/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -21829399.3197 - val_loss: -21512098.5175\n",
      "Epoch 545/600\n",
      "1617/1617 [==============================] - 0s 39us/sample - loss: -21086379.3989 - val_loss: -21615109.3986\n",
      "Epoch 546/600\n",
      "1617/1617 [==============================] - 0s 35us/sample - loss: -21964500.2536 - val_loss: -21719170.0559\n",
      "Epoch 547/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -21796789.9567 - val_loss: -21823187.9441\n",
      "Epoch 548/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -22237156.0297 - val_loss: -21930620.6853\n",
      "Epoch 549/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -23176980.9876 - val_loss: -22037518.4196\n",
      "Epoch 550/600\n",
      "1617/1617 [==============================] - 0s 28us/sample - loss: -22118006.3166 - val_loss: -22143251.6224\n",
      "Epoch 551/600\n",
      "1617/1617 [==============================] - 0s 29us/sample - loss: -22443006.5702 - val_loss: -22249156.4615\n",
      "Epoch 552/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -23323006.5900 - val_loss: -22358614.1818\n",
      "Epoch 553/600\n",
      "1617/1617 [==============================] - 0s 67us/sample - loss: -22865837.7205 - val_loss: -22466571.2587\n",
      "Epoch 554/600\n",
      "1617/1617 [==============================] - 0s 58us/sample - loss: -23257495.5003 - val_loss: -22575172.4476\n",
      "Epoch 555/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -23624862.2375 - val_loss: -22684903.0210\n",
      "Epoch 556/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -22647708.5220 - val_loss: -22791546.6993\n",
      "Epoch 557/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -23418362.3241 - val_loss: -22900159.3566\n",
      "Epoch 558/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -22701251.3878 - val_loss: -23007831.2308\n",
      "Epoch 559/600\n",
      "1617/1617 [==============================] - 0s 47us/sample - loss: -24209550.5318 - val_loss: -23117565.9021\n",
      "Epoch 560/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -23229863.5807 - val_loss: -23226717.8042\n",
      "Epoch 561/600\n",
      "1617/1617 [==============================] - 0s 50us/sample - loss: -22740907.3803 - val_loss: -23333660.4755\n",
      "Epoch 562/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -22526533.5844 - val_loss: -23437939.3427\n",
      "Epoch 563/600\n",
      "1617/1617 [==============================] - 0s 30us/sample - loss: -23574969.7873 - val_loss: -23547323.2448\n",
      "Epoch 564/600\n",
      "1617/1617 [==============================] - 0s 31us/sample - loss: -24002976.6778 - val_loss: -23657759.3986\n",
      "Epoch 565/600\n",
      "1617/1617 [==============================] - 0s 33us/sample - loss: -24238487.0031 - val_loss: -23768909.7762\n",
      "Epoch 566/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -22957283.5622 - val_loss: -23875738.5594\n",
      "Epoch 567/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -23462399.3315 - val_loss: -23984961.7063\n",
      "Epoch 568/600\n",
      "1617/1617 [==============================] - 0s 58us/sample - loss: -25189603.8367 - val_loss: -24098383.7483\n",
      "Epoch 569/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -24900024.6147 - val_loss: -24214447.4825\n",
      "Epoch 570/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -25968399.3160 - val_loss: -24332307.0909\n",
      "Epoch 571/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -25721322.3203 - val_loss: -24449643.8322\n",
      "Epoch 572/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -24847443.5745 - val_loss: -24563444.3776\n",
      "Epoch 573/600\n",
      "1617/1617 [==============================] - 0s 59us/sample - loss: -24124601.7934 - val_loss: -24673258.5594\n",
      "Epoch 574/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -25334657.3667 - val_loss: -24786849.2587\n",
      "Epoch 575/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -24508414.0012 - val_loss: -24899294.1818\n",
      "Epoch 576/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -25943871.0575 - val_loss: -25015887.9860\n",
      "Epoch 577/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -24653044.4230 - val_loss: -25128232.0979\n",
      "Epoch 578/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -25876099.8813 - val_loss: -25243595.1469\n",
      "Epoch 579/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -26850130.0000 - val_loss: -25364099.1748\n",
      "Epoch 580/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -25039426.4985 - val_loss: -25478708.1538\n",
      "Epoch 581/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -25199786.5578 - val_loss: -25590233.7343\n",
      "Epoch 582/600\n",
      "1617/1617 [==============================] - 0s 50us/sample - loss: -26246116.3537 - val_loss: -25708348.2378\n",
      "Epoch 583/600\n",
      "1617/1617 [==============================] - 0s 49us/sample - loss: -25441324.1694 - val_loss: -25822668.2098\n",
      "Epoch 584/600\n",
      "1617/1617 [==============================] - 0s 40us/sample - loss: -26102488.2573 - val_loss: -25938248.0000\n",
      "Epoch 585/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -27105339.4162 - val_loss: -26060060.0420\n",
      "Epoch 586/600\n",
      "1617/1617 [==============================] - 0s 42us/sample - loss: -25512693.1008 - val_loss: -26174278.7832\n",
      "Epoch 587/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -28153967.2183 - val_loss: -26296387.9021\n",
      "Epoch 588/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -25710719.4236 - val_loss: -26414189.2028\n",
      "Epoch 589/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -25914293.7737 - val_loss: -26528910.3077\n",
      "Epoch 590/600\n",
      "1617/1617 [==============================] - 0s 45us/sample - loss: -26963230.4341 - val_loss: -26645964.4895\n",
      "Epoch 591/600\n",
      "1617/1617 [==============================] - 0s 41us/sample - loss: -28262861.0229 - val_loss: -26772452.3916\n",
      "Epoch 592/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -27729204.0841 - val_loss: -26893681.1049\n",
      "Epoch 593/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -26560553.6772 - val_loss: -27012431.1888\n",
      "Epoch 594/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -27068088.6320 - val_loss: -27130319.7343\n",
      "Epoch 595/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -28926709.5312 - val_loss: -27254856.7692\n",
      "Epoch 596/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -27013857.7019 - val_loss: -27374212.1818\n",
      "Epoch 597/600\n",
      "1617/1617 [==============================] - 0s 52us/sample - loss: -26334973.1206 - val_loss: -27491614.0280\n",
      "Epoch 598/600\n",
      "1617/1617 [==============================] - 0s 44us/sample - loss: -28109143.1787 - val_loss: -27612381.3706\n",
      "Epoch 599/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -28378508.1670 - val_loss: -27735440.7413\n",
      "Epoch 600/600\n",
      "1617/1617 [==============================] - 0s 43us/sample - loss: -28029501.0736 - val_loss: -27858223.3846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16baccdca90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=600,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16bad0755f8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533.6464122377622\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test,predictions ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
